{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "import lightgbm as lgbm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X Train\n",
    "train = pd.read_csv(\"train_proje.csv\",  sep=\",\")\n",
    "x_test = pd.read_csv(\"test_proje.csv\",  sep=\",\")\n",
    "test_sample= pd.read_csv(\"test_ids_in_prediction.csv\", sep='|',  encoding='latin-1')\n",
    "\n",
    "list_array = test_sample.to_numpy()\n",
    "\n",
    "x_test_sample = x_test[x_test[\"unique_id\"].isin(list_array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0          0\n",
      "1          0\n",
      "2          0\n",
      "3          0\n",
      "4          0\n",
      "          ..\n",
      "5493263    1\n",
      "5493264    1\n",
      "5493265    1\n",
      "5493266    1\n",
      "5493267    1\n",
      "Name: gender, Length: 5493268, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "#Check all type train\n",
    "class3 = (train.iloc[:, -1] != 'train')*1\n",
    "print(sum(class3))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train['gender'] = le.fit_transform(train['gender'])\n",
    "\n",
    "print(train['gender'])\n",
    "\n",
    "train['time_stamp'] = pd.to_datetime(train['time_stamp'], \n",
    " format = '%Y-%m-%dT%H:%M:%SZ', \n",
    " errors = 'coerce')\n",
    "train['time_hour'] = train['time_stamp'].dt.hour\n",
    "\n",
    "\n",
    "x_test_sample['time_stamp'] = pd.to_datetime(x_test_sample['time_stamp'], \n",
    " format = '%Y-%m-%dT%H:%M:%SZ', \n",
    " errors = 'coerce')\n",
    "x_test_sample['time_hour'] = x_test_sample['time_stamp'].dt.hour\n",
    "\n",
    "\n",
    "means = train.groupby('user_action')['gender'].mean()\n",
    "train['user_action'] = train['user_action'].map(means)\n",
    "x_test_sample['user_action'] = x_test_sample['user_action'].map(means)\n",
    "\n",
    "means = train.groupby('businessunit')['gender'].mean()\n",
    "train['businessunit'] = train['businessunit'].map(means)\n",
    "x_test_sample['businessunit'] = x_test_sample['businessunit'].map(means)\n",
    "\n",
    "means = train.groupby('product_gender')['gender'].mean()\n",
    "train['product_gender'] = train['product_gender'].map(means)\n",
    "x_test_sample['product_gender'] = x_test_sample['product_gender'].map(means)\n",
    "\n",
    "\n",
    "\n",
    "train_drop=train.drop(columns=['time_stamp', 'contentid','product_name','brand_name','Level1_Category_Name','Level2_Category_Name','Level3_Category_Name','type'], axis=1)\n",
    "test_drop=x_test_sample.drop(columns=['time_stamp', 'contentid','product_name','brand_name','Level1_Category_Name','Level2_Category_Name','Level3_Category_Name','type'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features = 15)\n",
    "cv2 = CountVectorizer(max_features = 15)\n",
    "train['product_name'] = train['product_name'].fillna(\" \")\n",
    "train['brand_name'] = train['brand_name'].fillna(\" \")\n",
    "X_product = cv.fit_transform(train['product_name']).toarray()\n",
    "X_brand = cv2.fit_transform(train['brand_name']).toarray()\n",
    "X_product = pd.DataFrame(X_product)\n",
    "X_brand = pd.DataFrame(X_brand)\n",
    "X_brand.columns = [f'brandcol{i}' for i in range(0,len(X_brand.T))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_sample['product_name'] = x_test_sample['product_name'].fillna(\" \")\n",
    "x_test_sample['brand_name'] = x_test_sample['brand_name'].fillna(\" \")\n",
    "\n",
    "X_test_product = cv.transform(x_test_sample['product_name']).toarray()\n",
    "X_test_brand = cv2.transform(x_test_sample['brand_name']).toarray()\n",
    "X_test_product = pd.DataFrame(X_test_product)\n",
    "X_test_brand = pd.DataFrame(X_test_brand)\n",
    "X_test_brand.columns = [f'brandcol{i}' for i in range(0,len(X_test_brand.T))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_concat =pd.concat([train_drop, X_product,X_brand],  axis=1)\n",
    "X_concat =X_concat.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_concat =pd.concat([test_drop, X_test_product,X_test_brand],  axis=1)\n",
    "X_test_concat =X_test_concat.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 time_stamp   contentid  user_action  sellingprice  \\\n",
      "0                       NaT  39918893.0     0.065723       3099.00   \n",
      "1                       NaT   3558544.0     0.065723       3079.00   \n",
      "2                       NaT  31292729.0     0.065723       3999.00   \n",
      "3       2020-12-05 16:28:00   6363103.0     0.125061       2544.00   \n",
      "4       2020-12-02 22:26:59  39918893.0     0.125061       3099.00   \n",
      "...                     ...         ...          ...           ...   \n",
      "5493263 2020-12-09 11:41:59  31440796.0     0.160625         89.50   \n",
      "5493264 2020-12-09 00:10:16  54677237.0     0.160625         99.99   \n",
      "5493265 2020-12-09 11:40:57   2699559.0     0.160625        169.00   \n",
      "5493266                 NaT  34981546.0     0.065723        248.48   \n",
      "5493267 2020-12-09 10:44:35  34981546.0     0.125061        248.48   \n",
      "\n",
      "                                              product_name  brand_id  \\\n",
      "0        PerfectCare 600 EW6F449ST A+++ 9 KG 1400 Devir...    8511.0   \n",
      "1        WW90J5475FW A+++ 1400 Devir 9 kg Çamaşır Makinesi    3228.0   \n",
      "2                KM 9711 A++ 9 kg Çamaşır Kurutma Makinesi   10989.0   \n",
      "3           CMI 9710 A+++ 1000 Devir 9 kg Çamaşır Makinesi   10989.0   \n",
      "4        PerfectCare 600 EW6F449ST A+++ 9 KG 1400 Devir...    8511.0   \n",
      "...                                                    ...       ...   \n",
      "5493263             Turbo Profesyonel Saç Kurutma Makinesi   30457.0   \n",
      "5493264                             Erkek Gri Kot Pantolon  978383.0   \n",
      "5493265  Hd 6480 2200 Watt Difüzör Başlıklı İyonik Saç ...    8171.0   \n",
      "5493266                          Siyah Siyah Erkek Sneaker   93397.0   \n",
      "5493267                          Siyah Siyah Erkek Sneaker   93397.0   \n",
      "\n",
      "         brand_name  businessunit  product_gender  category_id  \\\n",
      "0        Electrolux      0.272579        0.151450       1272.0   \n",
      "1           Samsung      0.272579             NaN       1272.0   \n",
      "2            Vestel      0.272579        0.151450       1276.0   \n",
      "3            Vestel      0.272579             NaN       1272.0   \n",
      "4        Electrolux      0.272579        0.151450       1272.0   \n",
      "...             ...           ...             ...          ...   \n",
      "5493263    Powertec      0.211069        0.151450        864.0   \n",
      "5493264     ukdwear      0.570413        0.470852       1186.0   \n",
      "5493265     Grundig      0.211069        0.151450        864.0   \n",
      "5493266      Riccon      0.140228        0.470852        975.0   \n",
      "5493267      Riccon      0.140228        0.470852        975.0   \n",
      "\n",
      "         Level1_Category_Id Level1_Category_Name  Level2_Category_Id  \\\n",
      "0                    1071.0           Elektronik              1212.0   \n",
      "1                    1071.0           Elektronik              1212.0   \n",
      "2                    1071.0           Elektronik              1212.0   \n",
      "3                    1071.0           Elektronik              1212.0   \n",
      "4                    1071.0           Elektronik              1212.0   \n",
      "...                     ...                  ...                 ...   \n",
      "5493263              1071.0           Elektronik              2373.0   \n",
      "5493264               522.0                Giyim              2869.0   \n",
      "5493265              1071.0           Elektronik              2373.0   \n",
      "5493266               403.0             Ayakkabı               420.0   \n",
      "5493267               403.0             Ayakkabı               420.0   \n",
      "\n",
      "           Level2_Category_Name  Level3_Category_Id  Level3_Category_Name  \\\n",
      "0                    Beyaz Eşya              1272.0      Çamaşır Makinesi   \n",
      "1                    Beyaz Eşya              1272.0      Çamaşır Makinesi   \n",
      "2                    Beyaz Eşya              1276.0      Kurutma Makinesi   \n",
      "3                    Beyaz Eşya              1272.0      Çamaşır Makinesi   \n",
      "4                    Beyaz Eşya              1272.0      Çamaşır Makinesi   \n",
      "...                         ...                 ...                   ...   \n",
      "5493263  Kişisel Bakım Aletleri               864.0  Saç Kurutma Makinesi   \n",
      "5493264               Alt Giyim              1186.0                 Jeans   \n",
      "5493265  Kişisel Bakım Aletleri               864.0  Saç Kurutma Makinesi   \n",
      "5493266           Spor Ayakkabı               975.0               Sneaker   \n",
      "5493267           Spor Ayakkabı               975.0               Sneaker   \n",
      "\n",
      "         gender  unique_id   type  time_hour  \n",
      "0             0        425  train        NaN  \n",
      "1             0        425  train        NaN  \n",
      "2             0        425  train        NaN  \n",
      "3             0        425  train       16.0  \n",
      "4             0        425  train       22.0  \n",
      "...         ...        ...    ...        ...  \n",
      "5493263       1       7062  train       11.0  \n",
      "5493264       1       7062  train        0.0  \n",
      "5493265       1       7062  train       11.0  \n",
      "5493266       1       7062  train        NaN  \n",
      "5493267       1       7062  train       10.0  \n",
      "\n",
      "[5493268 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sellingprice  brand_id  businessunit  product_gender  category_id  \\\n",
      "0             3099.00    8511.0      0.272579        0.151450       1272.0   \n",
      "1             3079.00    3228.0      0.272579             NaN       1272.0   \n",
      "2             3999.00   10989.0      0.272579        0.151450       1276.0   \n",
      "3             2544.00   10989.0      0.272579             NaN       1272.0   \n",
      "4             3099.00    8511.0      0.272579        0.151450       1272.0   \n",
      "...               ...       ...           ...             ...          ...   \n",
      "5493263         89.50   30457.0      0.211069        0.151450        864.0   \n",
      "5493264         99.99  978383.0      0.570413        0.470852       1186.0   \n",
      "5493265        169.00    8171.0      0.211069        0.151450        864.0   \n",
      "5493266        248.48   93397.0      0.140228        0.470852        975.0   \n",
      "5493267        248.48   93397.0      0.140228        0.470852        975.0   \n",
      "\n",
      "         Level1_Category_Id  Level2_Category_Id  Level3_Category_Id  gender  \\\n",
      "0                    1071.0              1212.0              1272.0       0   \n",
      "1                    1071.0              1212.0              1272.0       0   \n",
      "2                    1071.0              1212.0              1276.0       0   \n",
      "3                    1071.0              1212.0              1272.0       0   \n",
      "4                    1071.0              1212.0              1272.0       0   \n",
      "...                     ...                 ...                 ...     ...   \n",
      "5493263              1071.0              2373.0               864.0       1   \n",
      "5493264               522.0              2869.0              1186.0       1   \n",
      "5493265              1071.0              2373.0               864.0       1   \n",
      "5493266               403.0               420.0               975.0       1   \n",
      "5493267               403.0               420.0               975.0       1   \n",
      "\n",
      "         unique_id  ...  brandcol5  brandcol6  brandcol7  brandcol8  \\\n",
      "0              425  ...          0          0          0          0   \n",
      "1              425  ...          0          0          0          0   \n",
      "2              425  ...          0          0          0          0   \n",
      "3              425  ...          0          0          0          0   \n",
      "4              425  ...          0          0          0          0   \n",
      "...            ...  ...        ...        ...        ...        ...   \n",
      "5493263       7062  ...          0          0          0          0   \n",
      "5493264       7062  ...          0          0          0          0   \n",
      "5493265       7062  ...          0          0          0          0   \n",
      "5493266       7062  ...          0          0          0          0   \n",
      "5493267       7062  ...          0          0          0          0   \n",
      "\n",
      "         brandcol9  brandcol10  brandcol11  brandcol12  brandcol13  brandcol14  \n",
      "0                0           0           0           0           0           0  \n",
      "1                0           0           0           0           0           0  \n",
      "2                0           0           0           0           0           0  \n",
      "3                0           0           0           0           0           0  \n",
      "4                0           0           0           0           0           0  \n",
      "...            ...         ...         ...         ...         ...         ...  \n",
      "5493263          0           0           0           0           0           0  \n",
      "5493264          0           0           0           0           0           0  \n",
      "5493265          0           0           0           0           0           0  \n",
      "5493266          0           0           0           0           0           0  \n",
      "5493267          0           0           0           0           0           0  \n",
      "\n",
      "[5493268 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sellingprice</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>businessunit</th>\n",
       "      <th>product_gender</th>\n",
       "      <th>category_id</th>\n",
       "      <th>Level1_Category_Id</th>\n",
       "      <th>Level2_Category_Id</th>\n",
       "      <th>Level3_Category_Id</th>\n",
       "      <th>gender</th>\n",
       "      <th>time_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>brandcol5</th>\n",
       "      <th>brandcol6</th>\n",
       "      <th>brandcol7</th>\n",
       "      <th>brandcol8</th>\n",
       "      <th>brandcol9</th>\n",
       "      <th>brandcol10</th>\n",
       "      <th>brandcol11</th>\n",
       "      <th>brandcol12</th>\n",
       "      <th>brandcol13</th>\n",
       "      <th>brandcol14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112.998954</td>\n",
       "      <td>61768.054009</td>\n",
       "      <td>0.129104</td>\n",
       "      <td>0.145483</td>\n",
       "      <td>1429.215213</td>\n",
       "      <td>939.982272</td>\n",
       "      <td>869.233972</td>\n",
       "      <td>1181.883323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.241093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.004527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121.377652</td>\n",
       "      <td>48010.564896</td>\n",
       "      <td>0.094103</td>\n",
       "      <td>0.098818</td>\n",
       "      <td>1219.593428</td>\n",
       "      <td>671.603745</td>\n",
       "      <td>1395.410011</td>\n",
       "      <td>1171.330276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.117363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.029539</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.029539</td>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198.018832</td>\n",
       "      <td>17295.436811</td>\n",
       "      <td>0.090940</td>\n",
       "      <td>0.053550</td>\n",
       "      <td>865.703986</td>\n",
       "      <td>538.132316</td>\n",
       "      <td>1870.700594</td>\n",
       "      <td>893.177269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.345518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470389</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>219.572958</td>\n",
       "      <td>57772.373535</td>\n",
       "      <td>0.108257</td>\n",
       "      <td>0.062563</td>\n",
       "      <td>1007.010384</td>\n",
       "      <td>872.498209</td>\n",
       "      <td>1767.441064</td>\n",
       "      <td>982.350641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.123366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.008804</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.002489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>118.082417</td>\n",
       "      <td>25966.406075</td>\n",
       "      <td>0.063604</td>\n",
       "      <td>0.094476</td>\n",
       "      <td>757.806642</td>\n",
       "      <td>827.649170</td>\n",
       "      <td>1663.762090</td>\n",
       "      <td>912.787687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.846085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.021709</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021061</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021709</td>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7991</th>\n",
       "      <td>925.000000</td>\n",
       "      <td>23155.000000</td>\n",
       "      <td>0.262792</td>\n",
       "      <td>0.151450</td>\n",
       "      <td>2604.000000</td>\n",
       "      <td>2859.000000</td>\n",
       "      <td>2469.000000</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7992</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>214948.000000</td>\n",
       "      <td>0.163814</td>\n",
       "      <td>0.151450</td>\n",
       "      <td>1714.000000</td>\n",
       "      <td>2859.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>1636.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>4699.000000</td>\n",
       "      <td>2765.000000</td>\n",
       "      <td>0.302382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2696.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1213.000000</td>\n",
       "      <td>2695.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>107.670000</td>\n",
       "      <td>40583.000000</td>\n",
       "      <td>0.112154</td>\n",
       "      <td>0.151450</td>\n",
       "      <td>2885.000000</td>\n",
       "      <td>758.000000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>2885.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>179.000000</td>\n",
       "      <td>997336.000000</td>\n",
       "      <td>0.108244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1850.000000</td>\n",
       "      <td>758.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>1846.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5618 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sellingprice       brand_id  businessunit  product_gender  \\\n",
       "unique_id                                                              \n",
       "1            112.998954   61768.054009      0.129104        0.145483   \n",
       "2            121.377652   48010.564896      0.094103        0.098818   \n",
       "3            198.018832   17295.436811      0.090940        0.053550   \n",
       "4            219.572958   57772.373535      0.108257        0.062563   \n",
       "5            118.082417   25966.406075      0.063604        0.094476   \n",
       "...                 ...            ...           ...             ...   \n",
       "7991         925.000000   23155.000000      0.262792        0.151450   \n",
       "7992          87.000000  214948.000000      0.163814        0.151450   \n",
       "7995        4699.000000    2765.000000      0.302382             NaN   \n",
       "7996         107.670000   40583.000000      0.112154        0.151450   \n",
       "7997         179.000000  997336.000000      0.108244             NaN   \n",
       "\n",
       "           category_id  Level1_Category_Id  Level2_Category_Id  \\\n",
       "unique_id                                                        \n",
       "1          1429.215213          939.982272          869.233972   \n",
       "2          1219.593428          671.603745         1395.410011   \n",
       "3           865.703986          538.132316         1870.700594   \n",
       "4          1007.010384          872.498209         1767.441064   \n",
       "5           757.806642          827.649170         1663.762090   \n",
       "...                ...                 ...                 ...   \n",
       "7991       2604.000000         2859.000000         2469.000000   \n",
       "7992       1714.000000         2859.000000          687.000000   \n",
       "7995       2696.000000         1071.000000         1213.000000   \n",
       "7996       2885.000000          758.000000          458.000000   \n",
       "7997       1850.000000          758.000000          476.000000   \n",
       "\n",
       "           Level3_Category_Id  gender  time_hour  ...  brandcol5  brandcol6  \\\n",
       "unique_id                                         ...                         \n",
       "1                 1181.883323     0.0  11.241093  ...   0.001440   0.004527   \n",
       "2                 1171.330276     0.0  15.117363  ...   0.007003   0.000382   \n",
       "3                  893.177269     0.0  17.345518  ...   0.000000   0.000000   \n",
       "4                  982.350641     0.0  15.123366  ...   0.000486   0.002489   \n",
       "5                  912.787687     0.0  15.846085  ...   0.000081   0.000567   \n",
       "...                       ...     ...        ...  ...        ...        ...   \n",
       "7991               797.000000     0.0        NaN  ...   0.000000   0.000000   \n",
       "7992              1636.000000     0.0  18.000000  ...   0.000000   0.000000   \n",
       "7995              2695.000000     1.0  20.000000  ...   0.000000   0.000000   \n",
       "7996              2885.000000     0.0   9.000000  ...   0.000000   0.000000   \n",
       "7997              1846.000000     0.0  12.000000  ...   0.000000   0.000000   \n",
       "\n",
       "           brandcol7  brandcol8  brandcol9  brandcol10  brandcol11  \\\n",
       "unique_id                                                            \n",
       "1           0.014815   0.000000   0.001235    0.000000    0.002058   \n",
       "2           0.029539   0.000255   0.004456    0.008149    0.002037   \n",
       "3           0.470389   0.000000   0.000000    0.000000    0.000000   \n",
       "4           0.003825   0.000425   0.002854    0.008804    0.000486   \n",
       "5           0.021709   0.000081   0.000000    0.021061    0.000729   \n",
       "...              ...        ...        ...         ...         ...   \n",
       "7991        0.000000   0.000000   0.000000    0.000000    0.000000   \n",
       "7992        0.000000   0.000000   0.000000    0.000000    0.000000   \n",
       "7995        0.000000   0.000000   0.000000    0.000000    0.000000   \n",
       "7996        0.000000   0.000000   0.000000    0.000000    0.000000   \n",
       "7997        0.000000   0.000000   0.000000    0.000000    0.000000   \n",
       "\n",
       "           brandcol12  brandcol13  brandcol14  \n",
       "unique_id                                      \n",
       "1            0.000000    0.014815    0.004527  \n",
       "2            0.000255    0.029539    0.000382  \n",
       "3            0.000000    0.470389    0.000000  \n",
       "4            0.000000    0.003825    0.002489  \n",
       "5            0.000000    0.021709    0.000567  \n",
       "...               ...         ...         ...  \n",
       "7991         0.000000    0.000000    0.000000  \n",
       "7992         0.000000    0.000000    0.000000  \n",
       "7995         0.000000    0.000000    0.000000  \n",
       "7996         0.000000    0.000000    0.000000  \n",
       "7997         0.000000    0.000000    0.000000  \n",
       "\n",
       "[5618 rows x 40 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q25_data = X_concat.groupby(['unique_id']).quantile(0.25)\n",
    "q75_data = X_concat.groupby(['unique_id']).quantile(0.75)\n",
    "mean = X_concat.groupby(['unique_id']).mean()\n",
    "option_2=(q75_data+q25_data+mean)/3\n",
    "option_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sellingprice</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>businessunit</th>\n",
       "      <th>product_gender</th>\n",
       "      <th>category_id</th>\n",
       "      <th>Level1_Category_Id</th>\n",
       "      <th>Level2_Category_Id</th>\n",
       "      <th>Level3_Category_Id</th>\n",
       "      <th>gender</th>\n",
       "      <th>time_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>brandcol5</th>\n",
       "      <th>brandcol6</th>\n",
       "      <th>brandcol7</th>\n",
       "      <th>brandcol8</th>\n",
       "      <th>brandcol9</th>\n",
       "      <th>brandcol10</th>\n",
       "      <th>brandcol11</th>\n",
       "      <th>brandcol12</th>\n",
       "      <th>brandcol13</th>\n",
       "      <th>brandcol14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>173.526771</td>\n",
       "      <td>18713.560348</td>\n",
       "      <td>0.085449</td>\n",
       "      <td>0.062929</td>\n",
       "      <td>878.035439</td>\n",
       "      <td>568.547388</td>\n",
       "      <td>2060.992102</td>\n",
       "      <td>952.541110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.012756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021805</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.453261</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>0.004442</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>0.453261</td>\n",
       "      <td>0.000808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>80.264474</td>\n",
       "      <td>49262.183008</td>\n",
       "      <td>0.089833</td>\n",
       "      <td>0.067643</td>\n",
       "      <td>910.425655</td>\n",
       "      <td>572.423496</td>\n",
       "      <td>1967.617921</td>\n",
       "      <td>962.304021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.576667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033039</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.436147</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>0.010402</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.009192</td>\n",
       "      <td>0.436147</td>\n",
       "      <td>0.001472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>200.800823</td>\n",
       "      <td>25928.801939</td>\n",
       "      <td>0.131055</td>\n",
       "      <td>0.104666</td>\n",
       "      <td>962.314097</td>\n",
       "      <td>517.613881</td>\n",
       "      <td>1621.595876</td>\n",
       "      <td>968.484918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.222163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011542</td>\n",
       "      <td>0.012773</td>\n",
       "      <td>0.053401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005694</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.004309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053401</td>\n",
       "      <td>0.012773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>179.700344</td>\n",
       "      <td>196286.698223</td>\n",
       "      <td>0.098820</td>\n",
       "      <td>0.100334</td>\n",
       "      <td>939.479779</td>\n",
       "      <td>677.887561</td>\n",
       "      <td>1462.180453</td>\n",
       "      <td>900.024203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.782090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014373</td>\n",
       "      <td>0.012844</td>\n",
       "      <td>0.049847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.049847</td>\n",
       "      <td>0.012844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>160.800237</td>\n",
       "      <td>81119.871064</td>\n",
       "      <td>0.109567</td>\n",
       "      <td>0.101321</td>\n",
       "      <td>1330.990946</td>\n",
       "      <td>844.346914</td>\n",
       "      <td>1036.050806</td>\n",
       "      <td>1228.377269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.790361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.040102</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.039859</td>\n",
       "      <td>0.002342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>89.950000</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>0.053585</td>\n",
       "      <td>0.052252</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>2871.000000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7990</th>\n",
       "      <td>729.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.315844</td>\n",
       "      <td>0.470852</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3330.000000</td>\n",
       "      <td>0.315844</td>\n",
       "      <td>0.151450</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>368.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>49.950000</td>\n",
       "      <td>8468.000000</td>\n",
       "      <td>0.302382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3517.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1213.000000</td>\n",
       "      <td>3517.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>69.900000</td>\n",
       "      <td>982770.000000</td>\n",
       "      <td>0.211459</td>\n",
       "      <td>0.151450</td>\n",
       "      <td>915.000000</td>\n",
       "      <td>758.000000</td>\n",
       "      <td>503.000000</td>\n",
       "      <td>2084.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sellingprice       brand_id  businessunit  product_gender  \\\n",
       "unique_id                                                              \n",
       "9            173.526771   18713.560348      0.085449        0.062929   \n",
       "18            80.264474   49262.183008      0.089833        0.067643   \n",
       "21           200.800823   25928.801939      0.131055        0.104666   \n",
       "25           179.700344  196286.698223      0.098820        0.100334   \n",
       "31           160.800237   81119.871064      0.109567        0.101321   \n",
       "...                 ...            ...           ...             ...   \n",
       "7982          89.950000    1042.000000      0.053585        0.052252   \n",
       "7990         729.000000      15.000000      0.315844        0.470852   \n",
       "7993           0.000000    3330.000000      0.315844        0.151450   \n",
       "7994          49.950000    8468.000000      0.302382             NaN   \n",
       "7998          69.900000  982770.000000      0.211459        0.151450   \n",
       "\n",
       "           category_id  Level1_Category_Id  Level2_Category_Id  \\\n",
       "unique_id                                                        \n",
       "9           878.035439          568.547388         2060.992102   \n",
       "18          910.425655          572.423496         1967.617921   \n",
       "21          962.314097          517.613881         1621.595876   \n",
       "25          939.479779          677.887561         1462.180453   \n",
       "31         1330.990946          844.346914         1036.050806   \n",
       "...                ...                 ...                 ...   \n",
       "7982        601.000000          522.000000         2871.000000   \n",
       "7990        425.000000          403.000000          420.000000   \n",
       "7993        448.000000          368.000000          435.000000   \n",
       "7994       3517.000000         1071.000000         1213.000000   \n",
       "7998        915.000000          758.000000          503.000000   \n",
       "\n",
       "           Level3_Category_Id  gender  time_hour  ...  brandcol5  brandcol6  \\\n",
       "unique_id                                         ...                         \n",
       "9                  952.541110     NaN  20.012756  ...   0.021805   0.000808   \n",
       "18                 962.304021     NaN  14.576667  ...   0.033039   0.001472   \n",
       "21                 968.484918     NaN  17.222163  ...   0.011542   0.012773   \n",
       "25                 900.024203     NaN  15.782090  ...   0.014373   0.012844   \n",
       "31                1228.377269     NaN  13.790361  ...   0.001656   0.002342   \n",
       "...                       ...     ...        ...  ...        ...        ...   \n",
       "7982               601.000000     NaN  21.000000  ...   0.000000   0.000000   \n",
       "7990               425.000000     NaN   8.000000  ...   0.000000   0.000000   \n",
       "7993               448.000000     NaN  11.000000  ...   0.000000   0.000000   \n",
       "7994              3517.000000     NaN        NaN  ...   0.000000   0.000000   \n",
       "7998              2084.000000     NaN  19.000000  ...   0.000000   0.000000   \n",
       "\n",
       "           brandcol7  brandcol8  brandcol9  brandcol10  brandcol11  \\\n",
       "unique_id                                                            \n",
       "9           0.453261   0.002423   0.004442    0.016354    0.002019   \n",
       "18          0.436147   0.008047   0.010402    0.004220    0.004514   \n",
       "21          0.053401   0.000000   0.005694    0.001847    0.004309   \n",
       "25          0.049847   0.000000   0.000612    0.000000    0.001223   \n",
       "31          0.040102   0.000081   0.001333    0.003069    0.004685   \n",
       "...              ...        ...        ...         ...         ...   \n",
       "7982        0.000000   0.000000   0.000000    0.000000    0.000000   \n",
       "7990        0.000000   0.000000   0.000000    0.000000    0.000000   \n",
       "7993        0.000000   0.000000   0.000000    0.000000    0.000000   \n",
       "7994        0.000000   0.000000   0.000000    0.000000    0.000000   \n",
       "7998        0.000000   0.000000   0.000000    0.000000    0.000000   \n",
       "\n",
       "           brandcol12  brandcol13  brandcol14  \n",
       "unique_id                                      \n",
       "9            0.002423    0.453261    0.000808  \n",
       "18           0.009192    0.436147    0.001472  \n",
       "21           0.000000    0.053401    0.012773  \n",
       "25           0.000917    0.049847    0.012844  \n",
       "31           0.000081    0.039859    0.002342  \n",
       "...               ...         ...         ...  \n",
       "7982         0.000000    0.000000    0.000000  \n",
       "7990         0.000000    0.000000    0.000000  \n",
       "7993         0.000000    0.000000    0.000000  \n",
       "7994         0.000000    0.000000    0.000000  \n",
       "7998         0.000000    0.000000    0.000000  \n",
       "\n",
       "[2380 rows x 40 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q25_data_test = X_test_concat.groupby(['unique_id']).quantile(0.25)\n",
    "q75_data_test = X_test_concat.groupby(['unique_id']).quantile(0.75)\n",
    "mean = X_test_concat.groupby(['unique_id']).mean()\n",
    "option_2_test=(q75_data_test+q25_data_test+mean)/3\n",
    "option_2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=option_2['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_2=option_2.drop(columns=['gender'], axis=1)\n",
    "option_2_test=option_2_test.drop(columns=['gender'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_2 = option_2.fillna(0)\n",
    "option_2_test = option_2_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_id\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       0.0\n",
      "4       0.0\n",
      "5       0.0\n",
      "       ... \n",
      "7991    0.0\n",
      "7992    0.0\n",
      "7995    1.0\n",
      "7996    0.0\n",
      "7997    0.0\n",
      "Name: gender, Length: 5618, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1939\n"
     ]
    }
   ],
   "source": [
    "print(sum(y==1)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3679\n"
     ]
    }
   ],
   "source": [
    "print(sum(y==0)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_2(trial):\n",
    "    train_data_2 = lgbm.Dataset(option_2, label=y) \n",
    "    params_2={\n",
    "        \"seed\": 2612,\n",
    "        \"boosting_type\":\"gbdt\",\n",
    "        \"metric\":\"auc\",\n",
    "        \"num_iterations\": trial.suggest_categorical(\"num_iterations\", [100, 300, 500,750, 1000,1500]),\n",
    "        \"max_depth\" :  trial.suggest_int(\"max_depth\", 3, 15),\n",
    "        \"num_leaves\" : trial.suggest_int('num_leaves', 20, 2**14),\n",
    "        \"subsample\" : trial.suggest_float('subsample', 0.2, 1.0) ,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
    "        \"num_threads\" : trial.suggest_int(\"num_threads\", 5, 135),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=10),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=10),\n",
    "        \"objective\": \"binary\",\n",
    "         \"is_unbalance\" : True,\n",
    "        \"early_stopping_rounds\" : 100,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    gbm_2 = lgbm.cv(params_2,\n",
    "           train_set=train_data_2, nfold=10,early_stopping_rounds=30,\n",
    "                    verbose_eval=False)\n",
    "    auc = np.mean((gbm_2[\"auc-mean\"]))\n",
    "    return auc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-24 13:34:20,140]\u001b[0m A new study created in memory with name: no-name-7e2de2fd-180a-4c41-aa6e-716d262b8e39\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:34:25,077]\u001b[0m Trial 0 finished with value: 0.8560992458989066 and parameters: {'num_iterations': 500, 'max_depth': 6, 'num_leaves': 9557, 'subsample': 0.3114962025727606, 'learning_rate': 0.04574405174768873, 'num_threads': 82, 'lambda_l1': 40, 'lambda_l2': 40}. Best is trial 0 with value: 0.8560992458989066.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:34:27,401]\u001b[0m Trial 1 finished with value: 0.8525067887342375 and parameters: {'num_iterations': 1500, 'max_depth': 3, 'num_leaves': 4360, 'subsample': 0.7529928561918358, 'learning_rate': 0.07809839822200292, 'num_threads': 115, 'lambda_l1': 90, 'lambda_l2': 70}. Best is trial 0 with value: 0.8560992458989066.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:34:30,808]\u001b[0m Trial 2 finished with value: 0.857518373983428 and parameters: {'num_iterations': 500, 'max_depth': 14, 'num_leaves': 941, 'subsample': 0.9442367880501366, 'learning_rate': 0.07082660396619056, 'num_threads': 24, 'lambda_l1': 30, 'lambda_l2': 40}. Best is trial 2 with value: 0.857518373983428.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:34:33,998]\u001b[0m Trial 3 finished with value: 0.8547577362932656 and parameters: {'num_iterations': 300, 'max_depth': 5, 'num_leaves': 15972, 'subsample': 0.7980517691347291, 'learning_rate': 0.02676280875028072, 'num_threads': 16, 'lambda_l1': 60, 'lambda_l2': 100}. Best is trial 2 with value: 0.857518373983428.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:34:36,661]\u001b[0m Trial 4 finished with value: 0.8535764005938867 and parameters: {'num_iterations': 100, 'max_depth': 6, 'num_leaves': 12367, 'subsample': 0.540099352747067, 'learning_rate': 0.09754140035512952, 'num_threads': 124, 'lambda_l1': 70, 'lambda_l2': 50}. Best is trial 2 with value: 0.857518373983428.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:35:12,777]\u001b[0m Trial 5 finished with value: 0.8557428473661803 and parameters: {'num_iterations': 1500, 'max_depth': 12, 'num_leaves': 2913, 'subsample': 0.915597927387461, 'learning_rate': 0.012547252783859885, 'num_threads': 70, 'lambda_l1': 40, 'lambda_l2': 80}. Best is trial 2 with value: 0.857518373983428.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:35:30,061]\u001b[0m Trial 6 finished with value: 0.8555749806599009 and parameters: {'num_iterations': 500, 'max_depth': 15, 'num_leaves': 6411, 'subsample': 0.49801913510670764, 'learning_rate': 0.08910947396313056, 'num_threads': 78, 'lambda_l1': 40, 'lambda_l2': 30}. Best is trial 2 with value: 0.857518373983428.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:35:34,401]\u001b[0m Trial 7 finished with value: 0.8562116611456473 and parameters: {'num_iterations': 100, 'max_depth': 7, 'num_leaves': 3704, 'subsample': 0.4786155799321494, 'learning_rate': 0.059509136200617714, 'num_threads': 60, 'lambda_l1': 20, 'lambda_l2': 100}. Best is trial 2 with value: 0.857518373983428.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:35:39,385]\u001b[0m Trial 8 finished with value: 0.853898993296234 and parameters: {'num_iterations': 750, 'max_depth': 6, 'num_leaves': 11843, 'subsample': 0.7039686339001496, 'learning_rate': 0.058722037873026725, 'num_threads': 117, 'lambda_l1': 80, 'lambda_l2': 100}. Best is trial 2 with value: 0.857518373983428.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:35:43,492]\u001b[0m Trial 9 finished with value: 0.8534269509767572 and parameters: {'num_iterations': 500, 'max_depth': 11, 'num_leaves': 14966, 'subsample': 0.2285372516857388, 'learning_rate': 0.04368177913235471, 'num_threads': 7, 'lambda_l1': 100, 'lambda_l2': 20}. Best is trial 2 with value: 0.857518373983428.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:36:02,027]\u001b[0m Trial 10 finished with value: 0.8597013877078781 and parameters: {'num_iterations': 1000, 'max_depth': 15, 'num_leaves': 142, 'subsample': 0.9714778221922504, 'learning_rate': 0.07291447317782397, 'num_threads': 35, 'lambda_l1': 0, 'lambda_l2': 10}. Best is trial 10 with value: 0.8597013877078781.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:36:29,326]\u001b[0m Trial 11 finished with value: 0.8541096515883009 and parameters: {'num_iterations': 1000, 'max_depth': 15, 'num_leaves': 451, 'subsample': 0.9742155042753514, 'learning_rate': 0.07059291712494181, 'num_threads': 36, 'lambda_l1': 0, 'lambda_l2': 0}. Best is trial 10 with value: 0.8597013877078781.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:36:48,915]\u001b[0m Trial 12 finished with value: 0.8545519092855588 and parameters: {'num_iterations': 1000, 'max_depth': 13, 'num_leaves': 566, 'subsample': 0.8461708148038981, 'learning_rate': 0.07627480127671211, 'num_threads': 38, 'lambda_l1': 0, 'lambda_l2': 0}. Best is trial 10 with value: 0.8597013877078781.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:36:54,054]\u001b[0m Trial 13 finished with value: 0.8590033738028049 and parameters: {'num_iterations': 1000, 'max_depth': 10, 'num_leaves': 470, 'subsample': 0.672053114480931, 'learning_rate': 0.06859463610056321, 'num_threads': 34, 'lambda_l1': 20, 'lambda_l2': 20}. Best is trial 10 with value: 0.8597013877078781.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:37:05,357]\u001b[0m Trial 14 finished with value: 0.8578440538202227 and parameters: {'num_iterations': 1000, 'max_depth': 10, 'num_leaves': 6781, 'subsample': 0.6482711403508298, 'learning_rate': 0.08629809588670523, 'num_threads': 50, 'lambda_l1': 10, 'lambda_l2': 20}. Best is trial 10 with value: 0.8597013877078781.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:37:15,714]\u001b[0m Trial 15 finished with value: 0.8600254324704567 and parameters: {'num_iterations': 1000, 'max_depth': 9, 'num_leaves': 2382, 'subsample': 0.41458860443633594, 'learning_rate': 0.05191656545400322, 'num_threads': 95, 'lambda_l1': 20, 'lambda_l2': 10}. Best is trial 15 with value: 0.8600254324704567.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:37:34,545]\u001b[0m Trial 16 finished with value: 0.8594869352773741 and parameters: {'num_iterations': 1000, 'max_depth': 8, 'num_leaves': 2966, 'subsample': 0.38181739517718716, 'learning_rate': 0.042977871814103154, 'num_threads': 97, 'lambda_l1': 10, 'lambda_l2': 0}. Best is trial 15 with value: 0.8600254324704567.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:37:51,586]\u001b[0m Trial 17 finished with value: 0.8579259277449541 and parameters: {'num_iterations': 300, 'max_depth': 9, 'num_leaves': 5480, 'subsample': 0.40152237455444245, 'learning_rate': 0.029270666882418448, 'num_threads': 96, 'lambda_l1': 20, 'lambda_l2': 10}. Best is trial 15 with value: 0.8600254324704567.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:38:27,056]\u001b[0m Trial 18 finished with value: 0.8582102087475023 and parameters: {'num_iterations': 750, 'max_depth': 12, 'num_leaves': 8655, 'subsample': 0.2025073675277277, 'learning_rate': 0.05328220451686677, 'num_threads': 55, 'lambda_l1': 0, 'lambda_l2': 60}. Best is trial 15 with value: 0.8600254324704567.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:38:36,873]\u001b[0m Trial 19 finished with value: 0.8547418056699242 and parameters: {'num_iterations': 1000, 'max_depth': 9, 'num_leaves': 2561, 'subsample': 0.5709013364544913, 'learning_rate': 0.031908156549158274, 'num_threads': 99, 'lambda_l1': 50, 'lambda_l2': 30}. Best is trial 15 with value: 0.8600254324704567.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:38:40,596]\u001b[0m Trial 20 finished with value: 0.8574179834574672 and parameters: {'num_iterations': 1000, 'max_depth': 3, 'num_leaves': 1976, 'subsample': 0.4219686691451082, 'learning_rate': 0.05282533038069278, 'num_threads': 86, 'lambda_l1': 10, 'lambda_l2': 10}. Best is trial 15 with value: 0.8600254324704567.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:39:01,837]\u001b[0m Trial 21 finished with value: 0.8596655915527545 and parameters: {'num_iterations': 1000, 'max_depth': 8, 'num_leaves': 4601, 'subsample': 0.3688771668559417, 'learning_rate': 0.04025460009378108, 'num_threads': 104, 'lambda_l1': 10, 'lambda_l2': 0}. Best is trial 15 with value: 0.8600254324704567.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:39:13,939]\u001b[0m Trial 22 finished with value: 0.8590772743698696 and parameters: {'num_iterations': 1000, 'max_depth': 8, 'num_leaves': 4800, 'subsample': 0.31438891066444286, 'learning_rate': 0.03681526350669998, 'num_threads': 132, 'lambda_l1': 30, 'lambda_l2': 10}. Best is trial 15 with value: 0.8600254324704567.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:39:56,251]\u001b[0m Trial 23 finished with value: 0.8596475812677181 and parameters: {'num_iterations': 1000, 'max_depth': 10, 'num_leaves': 1903, 'subsample': 0.32070837973790123, 'learning_rate': 0.019912143954870884, 'num_threads': 109, 'lambda_l1': 10, 'lambda_l2': 0}. Best is trial 15 with value: 0.8600254324704567.\u001b[0m\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:573: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-01-24 13:40:02,481]\u001b[0m Trial 24 finished with value: 0.8575748167458143 and parameters: {'num_iterations': 1000, 'max_depth': 8, 'num_leaves': 7403, 'subsample': 0.6128431621676254, 'learning_rate': 0.06268145416490942, 'num_threads': 106, 'lambda_l1': 30, 'lambda_l2': 10}. Best is trial 15 with value: 0.8600254324704567.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 25\n",
      "Best trial:\n",
      "  Value: 0.8600254324704567\n",
      "  Params: \n",
      "    num_iterations: 1000\n",
      "    max_depth: 9\n",
      "    num_leaves: 2382\n",
      "    subsample: 0.41458860443633594\n",
      "    learning_rate: 0.05191656545400322\n",
      "    num_threads: 95\n",
      "    lambda_l1: 20\n",
      "    lambda_l2: 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "sampler= optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler,pruner=optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=2, n_warmup_steps=5, interval_steps=3\n",
    "    ),direction=\"maximize\")\n",
    "study.optimize(objective_2, n_trials=25)\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(option_2, y, test_size = 0.15, random_state = 1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1648, number of negative: 3127\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9938\n",
      "[LightGBM] [Info] Number of data points in the train set: 4775, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345131 -> initscore=-0.640512\n",
      "[LightGBM] [Info] Start training from score -0.640512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttraining's auc: 0.872214\tvalid_1's auc: 0.843596\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\ttraining's auc: 0.875749\tvalid_1's auc: 0.848408\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\ttraining's auc: 0.880509\tvalid_1's auc: 0.847347\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\ttraining's auc: 0.885748\tvalid_1's auc: 0.850886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\ttraining's auc: 0.889565\tvalid_1's auc: 0.853762\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\ttraining's auc: 0.893217\tvalid_1's auc: 0.855331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttraining's auc: 0.895621\tvalid_1's auc: 0.855984\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttraining's auc: 0.897802\tvalid_1's auc: 0.856663\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\ttraining's auc: 0.900106\tvalid_1's auc: 0.85713\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's auc: 0.902273\tvalid_1's auc: 0.85751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[110]\ttraining's auc: 0.904228\tvalid_1's auc: 0.85769\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttraining's auc: 0.905745\tvalid_1's auc: 0.857286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[130]\ttraining's auc: 0.907228\tvalid_1's auc: 0.857217\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[140]\ttraining's auc: 0.907441\tvalid_1's auc: 0.857149\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[150]\ttraining's auc: 0.907441\tvalid_1's auc: 0.857149\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[160]\ttraining's auc: 0.907441\tvalid_1's auc: 0.857149\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[170]\ttraining's auc: 0.907441\tvalid_1's auc: 0.857149\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[180]\ttraining's auc: 0.907441\tvalid_1's auc: 0.857149\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[190]\ttraining's auc: 0.907441\tvalid_1's auc: 0.857149\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[200]\ttraining's auc: 0.907441\tvalid_1's auc: 0.857149\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Early stopping, best iteration is:\n",
      "[104]\ttraining's auc: 0.903155\tvalid_1's auc: 0.85784\n",
      "defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.9031551845653734)]), 'valid_1': OrderedDict([('auc', 0.8578396583495194)])})\n"
     ]
    }
   ],
   "source": [
    "train_data = lgbm.Dataset(X_train,y_train)\n",
    "valid_data = lgbm.Dataset(X_test,y_test)\n",
    "\n",
    "config_params = {\n",
    "    \"classification\" : {\n",
    "                \"seed\": 2612,\n",
    "                \"boosting_type\":\"gbdt\",\n",
    "                \"metric\":\"auc\",\n",
    "                \"colsample_bytree\" : 0.9,\n",
    "                \"objective\": \"binary\",\n",
    "                 \"is_unbalance\" : True,\n",
    "                \"early_stopping_rounds\" : 100,\n",
    "\n",
    "        }\n",
    "   \n",
    "    \n",
    "   }\n",
    "config_params[\"classification\"].update(study.best_params)\n",
    "config_params[\"classification\"][\"n_estimators\"] = study.best_params[\"num_iterations\"]#It is equal to 1000\n",
    "lgb_model =lgbm.train(config_params[\"classification\"],train_data,valid_sets=[train_data,valid_data],verbose_eval=10)\n",
    "score = lgb_model.best_score\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04864369 0.0638848  0.06578682 ... 0.6198926  0.53479867 0.70944813]\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgb_model.predict(option_2_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n"
     ]
    }
   ],
   "source": [
    "explainer = shap.TreeExplainer(lgb_model)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAI0CAYAAAA5sKwKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZRdVZn38W9BghAhjAmIgYRJacVuun0EURRtlLdbKLFtEFpohogyiEwxoL6IUWwRDLBExQYJAgIKIoPF1IAttnHMgyIOL82USiCAYUhCEmgwyX3/OLv0Ul2VGk4lN5X6ftaqdU+dfc4+z7m5a+W39t73VFuj0UCSJEmDs06rC5AkSRrODFOSJEk1GKYkSZJqMExJkiTVYJiSJEmqYVSrC9Dw1NHR0Whvb291GZIkrS5tvTU4MiVJklSDYUqSJKkGw5QkSVINhilJkqQaDFOSJEk1GKYkSZJqMExJkiTVYJiSJEmqwTAlSZJUg2FKkiSpBsOUJElSDYYpSZKkGgxTkiRJNRimJEmSajBMSZIk1dDWaDRaXYOGobbpy/zgSEOkMfWAVpcgrV0aN66KXtt6a3BkSpIkqQbDlCRJUg2GKUmSpBoMU5IkSTWstWEqIjoj4tBV0O+nIqJjqPtd3SLikIj4TavrkCRpuBvV6gKGm8z8QqtrGAqZeRVwVdfvEXEZsCwzj2pZUZIkDUNr7ciUJEnS6rC2j0xtHxEzgV2B+4FjM3NWT6MwEdEJnJ6ZV0bEJOAiYHegATwCfDAz/zsipgF7Zua7ms67GNi7HN8JfCQzf9rU94eBE4FtSl+nZeYdpe1vga8AbwCWlzr3zcwFEXEw8BlgAvA8cFtmHlHOawBvy8yZ5fd3AHdl5qjy+93APcAkYB9gPnBKZt5U2o8o97tjRJwKHFL2H1zK3jgzlw/8LZckaWRZ20emjqEKMZsB1wG3RsTYfpz3BWAusCWwBXAksHAlx08GTgA2Bu4ELu9qiIiPAKdRhZVNgf8LXB8RO5ZDvgbcUWrcEjgFeCkixgDfAj6amRsB2wMz+lF7s8OB80pdXwUuL/2+TGaeQzXld3lmblh+DFKSJPXD2j4yNSMz7wGIiLOB44D9+nHeS8BWwPaZ+f+A+/o4/qLM/H25ziXASRGxcWYuogpZn8vMrsXet0bED4GDgc+Xa20LbJOZncDPSz9jgD8BO0fEvZn5LPDjft53l2sy8yelv4upgtVOgAvPJUkaImv7yFRn10ZmNqhGmyb047ypwGygIyKeiIivRMSGKzn+iabtpeV1o/K6HfC1iFjY9QO8E3h1aT+S6t9hZkTMjogzI2JUZj4PvAf4B+DhiLgnIj7Yj9p7rCszu9clSZKGwNo+MjWpayMi2qhGgB4rr5s3tY0Cxnf9nplPUY0onRAR2wM3AacCZwyihjnAZzLzuz01ZuZsqmlCIuINVFN+s4FLM/Nu4O6IWBd4L/C9iPhFZj5MFdpe2dTV1oOordmKmudLkjQire1hanJE3AD8FjgZGAPcAqwHnBMR2wGPA58DRnedFBEHAb+kGtlaRDUVt2yQNZwPTIuIB6mm19YH3gg8nZn3R8ThwJ2Z+TjVuqxlwLKI2BLYk2pR+aIyogXVInWABA4vU4ZbU621quNJ4M0RsU5mGqwkSeqntX2a72LgAmABcBDVt+QWUS22/j7wK+Bhqum/eU3n/S3wI2AJ8Pty3PTBFJCZ3wDOAb5Z6pgLfJq/hLe/B+6JiCXAz4CrS33rAB8FOiNiMdVC9cPLuiqA44EdgWeBa4HLBlNfk0uoRrqeKdOR69bsT5KkEaGt0Wi0ugYNQ23Tl/nBkYZIY+oBrS5BWrs0blwVvbb11rC2j0xJkiStUoYpSZKkGpzm06B0dHQ02tvbW12GJEmri9N8kiRJq4JhSpIkqQbDlCRJUg2GKUmSpBoMU5IkSTUYpiRJkmrw0QgaFJ+ArtXNp4RrtVs1T9HW8OWjESRJklYFw5QkSVINhilJkqQaRkyYioi7ImJaq+tYXUba/UqS1CojJkwNpYi4OyJOb3UdkiSp9YZdmIqI0a2uYW0XEetGxLD7bEiS1AqjWl0AQER0ApcC+wC7AvcDx2bmrIi4DBgNvATsD1wDHBsRxwInAVsB/w+Ympk/Lv21AZ8APgqMAS6n6SuNEfEO4K7MHNW0bxqwZ2a+q/w+Dvgi8G5gE+BB4IPAx4C3AXtExCeAeZn52j7ub3fgQuA1wG+AO4DJmTmptI8BPgf8M7Ax8Evg+Mx8qLTfDdwDTCrv0XzglMy8qT/3W47ZBTgXeCPwPHAVcEZm/ikiJgGzgaOAKcAOwETgyZXdlyRJWrNGpo4BTgQ2A64Dbo2IsaXtQOB2YBwwJSL+BTgTOAzYHPgGcHtETCzHHwqcTBW+tgKeBt7e30LKqMxNVCHqTeX1SGBxZh4P/Bg4MzM37EeQ2hi4FfhOubePAUd3O+wSYGfgzaXeXwA3dxuFOxw4jypsfRW4vISwPu83IsYDPwKuB7YG9qAKiZ/sVscHgb8HNgKeWtl9SZKkyhoxMlXMyMx7ACLibOA4YL/SNjMzrynbz0fEkcBFmfmLrnMj4iiqMHAWVci6qKm/s6jCWn8FVYjaIjMXlX33DfK+2oElwPTMbAC/johLgX8ttW0B/AswMTP/WPZ9lmrUbXdgZunnmsz8SWm/mCpY7UQ10tXX/R4G/CYzLyq/zyvHnE01Itbls5npaJQkSQOwJo1MdXZtlNAxF5jQva3YBnik276Hy37Kec39rQDmDKCWScD8piBVx6uBueWeujTXsl15vS8iFkbEQuBZqqnNbZqOe6JrIzOXls2Nymtf97sd8Nau/ss1LqUaxWrWiSRJGpA1aWRqUtdGWQO0LfAY8DpgRbdjH+UvIaTL9kBH2Z7XQ38Tm45dAqwbEa/IzBfLvq2b2juB8RExNjOf66HW7vWszDxg24hoawpU2za1d4WenTJzsFNrfd3vHKo1Yvv20c9A7kuSJLFmhanJEXED8Fuq9T9jgFuoFlx3dxnw5Yj4PvArqjVDu1JN8wF8Czinqb+P8/JRmP+mClRHRcTXgbcAB5S+AJJqwfclEXE81Rqk1wNPZ+YTVAuzd+znfd0MXACcEhEXUIXDI4HlAJk5PyKuBi6MiJMyc15EbAK8E7gzM5f04xp93e8VVGvNJgNXUy3mnwS8JjNv7+d9SJKkHqxJ03wXU4WOBcBBwL69TbNl5tXAZ4ErgWeo1le9JzM7yyFXAF+hGqn6IzAe+K+m8xdTBZopwCKqhe+XN7WvAN4LvADcCywEvslfptXOB6JMmf1+ZTeVmQuBfYFDyr19jSoMvth02IepAt7dEbGYKhAdCPT3jwn3db9PUoWz91GNui0AbqAazZMkSTW0NRr9/f961SmPRjg9M69sdS2rQ1n8/cbM7GnUbVhom76s9R8cjSiNqQe0ugSNNI0bW12B1ixtvTWsSdN8a62IeDfwO6pRo7cCH6GaipMkScOcYWoIlKm+iT00zcnM1wNvoFrXNBZ4HPgSTdOKkiRp+Fojpvk0/HR0dDTa29tbXYYkSatLr9N8a9ICdEmSpGHHMCVJklSDYUqSJKkGw5QkSVINhilJkqQaDFOSJEk1GKYkSZJq8DlTGhT/nMzaxT/VshbxT6BIq4rPmZIkSVoVDFOSJEk1GKYkSZJqMExJkiTVMKrVBWjNEBHrADOBPYBtMvOxFpckSdKw4MiUupwMPN/qIiRJGm4MUyIiXgMcB3y81bVIkjTcGKZGuDK9dykwFVjY4nIkSRp2DFM6EXgyM69vdSGSJA1HLkAfwSJiR2AKEK2uRZKk4cqRqZFtT2Ac8LuIeBr4Vdl/X0Qc17qyJEkaPhyZGtmuBe5q+n0C8DNgH+D+llQkSdIwY5gawTLzeZoehxARXZ+HJzNzSWuqkiRpeDFM6c8ys5OV/FVsSZL0v7lmSpIkqQbDlCRJUg1tjUaj1TVoGOro6Gi0t7e3ugxJklaXXpfBODIlSZJUg2FKkiSpBsOUJElSDYYpSZKkGgxTkiRJNRimJEmSavDRCBqUtunL/OAMA42pB7S6BPVH48ZWVyCpbz4aQZIkaVUwTEmSJNVgmJIkSarBMCVJklSDYWolIqIzIg5tcQ2HRkTnEPV1WURcMhR9SZKkyqhWF6DWiYgl3XaNpvpMbJmZT7egJEmShh3D1BCJiNGZ+adW1zEQmblh8+8RcRWwqUFKkqT+M0z1bfuImAnsCtwPHJuZsyLiMqqRnJeA/YFrImIKcCXwFmAM8BBwWmbeCRARRwCnAxcApwKvBK4FjsvM5eWY3YALgZ2Be4E7mouJiA2BacD7gXHAXODozJwZEWOAs0rbBsBM4ITMnNvXTUbE5sA/Ax8Y8DskSdII5pqpvh0DnAhsBlwH3BoRY0vbgcDtVKFmCtX7eT2wE7A58G3gexExrqm/icCWwA7Am0ofBwNExMbAbeU6mwEnA8d1q2cGsDuwNzAWeB/wZGk7H3hz+ZkIPA10RMS6/bjPI4GngFv6cawkSSocmerbjMy8ByAizqYKN/uVtpmZeU3Zfr68Xtl07pci4jSq0HRr2fcCcEYZiXooIn4ABHBV6XcpcHZmNoBZETEDOKRcfzzVyNEumTm79PdgaVsHOAx4b2bOK/tOAp4FdgN+1tsNRkQb8BHgkq4RMkmS1D+Gqb51dm1kZiMi5gITurcBRMQGwDnAvsAWwApgI6qRqy7zuwWWpeUYSr9zSpDqMrtpe1J5faCHOscB6wOPNNW7JCLmA9uwkjAFvBPYHvCbfpIkDZDTfH2b1LVRRnC2BR4ru1Z0O/YUYC+qKbiNM3MTYAEr+Xs+3cwDJpbrdNmuabuzvO7Uw7lPAS82H1/WV40HHu3juscAHV0jWpIkqf8cmerb5Ii4Afgt1RqmMVTrivbp4dixVIHmGWC9MsW3yQCudTPV4vSpEXE+8AZgcumTzJwfEdcBF5bF7HOo1l6RmQ9FxBXAmRHxB2AhcC7Vovlf9nbBMnX4PqB9AHVKkqTCkam+XUwVcBYABwH7ZuaiXo49jyrEPA48TLWOqrO/F8rMhVRThAeV610AfL3bYZOpvuX3I2AxcBOwVWk7GUhgFtW3/F5FtYZqZeugJlONtN2xkmMkSVIv2hqNRt9HSd20TV/mB2cYaEw9oNUlqD8aN7a6Akl963XJjiNTkiRJNTgypUHp6OhotLe7zEqSNGI4MiVJkrQqGKYkSZJqMExJkiTVYJiSJEmqwTAlSZJUg2FKkiSpBsOUJElSDT5nSoPiE9BXD59gvpr4BHJJffM5U5IkSauCYUqSJKkGw5QkSVINhilJkqQaRrW6ALVeRLwL+DywC/A/wLWZeVxrq5IkaXgwTI1wEfEO4DrgKKCD6tsKr2tlTZIkDSeGKZ0F/HtmXte071etKkaSpOHGMDWCRcQrgd2A/4iIXwHbAr8DPp6Z2dLiJEkaJlyAPrJtSvUZ+DBwBLA1cAdwa0Rs0sK6JEkaNgxTI9vi8vrNzLwvM1+imvYbDbyldWVJkjR8GKZGsMxcBHQCPf1pGP9cjCRJ/eCaKV0InBgR3wYeAE6hejzCT1talSRJw4RhStOBjYD/BNYHfg38Yxm1kiRJfWhrNJzN0cC1TV/mB2c1aEw9oNUljAyNG1tdgaQ1X1tvDa6ZkiRJqsEwJUmSVIPTfBqUjo6ORnt7e6vLkCRpdXGaT5IkaVUwTEmSJNVgmJIkSarBMCVJklSDYUqSJKkGw5QkSVINPhpBg7I6n4C+Wp8C7pOwJUk989EIkiRJq4JhSpIkqQbDlCRJUg2GKUmSpBoMU5IkSTWManUBaq2IOBvYD9gGWALcApyWmc+2tDBJkoYJR6a0HDgU2Bz4G2AC8M2WViRJ0jDiyNQIl5mfavr1qYj4KnB1q+qRJGm4cWRK3e0N3NfqIiRJGi4cmdKfRcQ/Ax8G9mp1LZIkDReOTAmAiDgQ+Abw3sz8VavrkSRpuDBMiYg4ErgIaM/MH7a6HkmShhPD1AgXEScA04H/k5k/aXU9kiQNN66Z0peBZcAPI+LPOzNzw5ZVJEnSMGKYGuEys63VNUiSNJw5zSdJklSDYUqSJKmGtkaj0eoaNAx1dHQ02tvbW12GJEmrS6/LYhyZkiRJqsEwJUmSVINhSpIkqQbDlCRJUg2GKUmSpBoMU5IkSTX4aAQNStv0ZUP+wWlMPWCouywd37hq+pUkjSQ+GkGSJGlVMExJkiTVYJiSJEmqwTA1ABHRGRGHlu1JEdGIiAnl90Mi4jetrRAi4lMR0dHqOiRJGilGtbqAtUVmXgVctQbU8YVW1yBJ0kjiyNRaIiLaIsJwLEnSajYi//ONiBOAk4EtgOeAyzPzUxGxLXAe8NZyaAcwJTMX96PPI4DTM3PH8vvdwD3AJGAfYD5wSmbeVNrbgE8CxwFjgMuBvwZ+nJnTIuIdwF3Ah4DPARsB3weOz8wlpY8GcBLwr8DrgXdGxD8Ae2bmu8oxGwLTgPcD44C5wNGZObOEr1OBI4DxwO+BEzLznn6/mZIkjXAjbmQqIl4DfBHYLzM3ogoh34+I9YH/BP4AbA+8DpgAfLnG5Q6nCmcbA18FLo+IMaXtX4ETgXZgS+AJ4O3dzl+3tP818FfAa4Bzux3zIeAgYEPg1z3UMAPYHdgbGAu8D3iytH0O2B/4B2Bz4FLgPyJi04HfqiRJI9NIHJlaRvXgrddHxJzMXAj8PCIOANoy84xy3AsR8WngpxHx4cxcPohrXZOZPwGIiIupgtVOwG+Aw4CLMvPXpf1LwEd76OO0zFwELIqIM4CbI+LYzFxR2qdn5sNle3lE/PnEiBgPfADYJTNnl90PlrY24GPAvpn5SGmbEREnAfsCVw7ifiVJGnFGXJjKzEci4hDgWOCSiLiPaoRmO2DbiFjY7ZQGsBUwbxCXe6LpuktL0Nmo7Ho1MKepvRERj/bQx5ym7U7gFVTTk/Ob9vVmUnl9oIe2LahGszrKdGGX0VQjcpIkqR9GXJgCyMzrgesjYj3gGOAm4Gjggcx8/WoqYx4wseuXMlK0TQ/HTQS6Rp4mAS8CTze1r+h+QpPO8roT1fRls6eBpcC7MnNWf4uWJEkvN+LCVES8lmoU6r+AF4BFVKNP1wGnR8SngK8AS4Ctgd0y84ZVUMq3gLMj4ntUQeeEcr3uzoqIo4D1qRaSf6tpim+lMnN+RFwHXFgWyM8BdihtD0XEl4HpEXFUZj5YFqu/FfhtZj5e7/YkSRoZRtwCdGA94DNUU3ALqULMP2fm81SLtF8H3E8Vsn4A7LqK6rgC+BpwG/BHqqm1n1ONPHVZDtwC/Bb4b+AR4JQBXmcycC/wI2Ax1SjcVqXtM+X3myLiOar1VMcwMj8XkiQNSluj0ej7KK1yEbEO1WMLTs3Mq7sejZCZa+ToYdv0ZUP+wWlMPWCouywd37hq+pUkjSRtvTWskf9RjxQRcRDVyNA6VM+ceiXVSJUkSRomnM5prY9RTfE9Afw98J7MXNDakiRJ0kA4zadB6ejoaLS3t7e6DEmSVpdep/kcmZIkSarBMCVJklSDYUqSJKkGw5QkSVINhilJkqQaDFOSJEk1GKYkSZJq8DlTGpRh8+dk/FMykqSh4XOmJEmSVgXDlCRJUg2GKUmSpBoMU5IkSTWManUBaq2IuAw4BHixafepmXlhayqSJGl4MUwJ4PLMPKrVRUiSNBw5zSdJklSDI1MC+OeIeD/wNHAT8NnMXNLimiRJGhYcmdJXgJ2BLYB/AvYCvtHSiiRJGkZ8ArpeJiLeCtwNbJiZL/Z2nE9AlySNMD4BXf22orz2+qGRJEl/YZga4SLi4IjYpGzvBJwLfD8z/6e1lUmSNDwYpnQM8EhELAXuAH4OHNnakiRJGj78Nt8Il5nvaHUNkiQNZ45MSZIk1WCYkiRJqsFHI2hQOjo6Gu3t7a0uQ5Kk1cVHI0iSJK0KhilJkqQaDFOSJEk1GKYkSZJqMExJkiTVYJiSJEmqwUcjaFDapi8b8g9OY+oBQ90lNG4c+j4lSSORj0aQJElaFQxTkiRJNRimJEmSajBMSZIk1WCYWomI6IyIQ1tcw6ER0TlEfV0WEZcMRV+SJKkyqtUFqHUi4lLg3cDGwFLgNmBKZi5oaWGSJA0jjkwNkYgY3eoaBuE8YOfMHAv8FTAG+FprS5IkaXhxZKpv20fETGBX4H7g2MycFRGXAaOBl4D9gWsiYgpwJfAWqmDyEHBaZt4JEBFHAKcDFwCnAq8ErgWOy8zl5ZjdgAuBnYF7gTuai4mIDYFpwPuBccBc4OjMnBkRY4CzStsGwEzghMyc29ONZebvuu1aAbx2wO+QJEkjmCNTfTsGOBHYDLgOuDUixpa2A4HbqULNFKr383pgJ2Bz4NvA9yJiXFN/E4EtgR2AN5U+DgaIiI2pptquK9c7GTiuWz0zgN2BvYGxwPuAJ0vb+cCby89E4GmgIyLW7e3mIuITEbEYWFD6+rf+vS2SJAkcmeqPGZl5D0BEnE0VbvYrbTMz85qy/Xx5vbLp3C9FxGlUoenWsu8F4IwyEvVQRPwACOCq0u9S4OzMbACzImIGcEi5/njgA8AumTm79PdgaVsHOAx4b2bOK/tOAp4FdgN+1tPNZeYXgS9GxHbAZKrRNEmS1E+OTPWts2ujBJy5wITubQARsUFEfCUiHomI5yJiIbAp1chVl/ldU3rFUmCjsj0BmFOu02V20/ak8vpAD3WOA9YHHmmqdwkwH9hmJffXdexsoINq5M3PhSRJ/eR/mn2b1LUREW3AtsBjZdeKbseeAuxFNQW3cWZuQjV91uvf8+lmHjCxXKfLdk3bneV1px7OfQp4sfn4sr5qPPBoP68/Cng11VouSZLUD07z9W1yRNwA/JZqDdMY4BZgnx6OHUsVaJ4B1itTfJsM4Fo3Uy1OnxoR5wNvoJp6exEgM+dHxHXAhWUx+xyqtVdk5kMRcQVwZkT8AVgInEu1aP6X3S9Upgz/Afh+Zi6MiNcA51BNXS4eQM2SJI1ojkz17WKqgLMAOAjYNzMX9XLseVQh5nHgYap1VJ39vVBmLgT2LddZUK779W6HTab6lt+PgMXATcBWpe1kIIFZVNORr6JaQ7Wc/60BHAE8EhFLgTuB3wEH9LdeSZIEbY1Go++jpG7api8b8g9OY+oqyHGNG4e+T0nSSNTrkh1HpiRJkmpwZEqD0tHR0Whvb291GZIkrS6OTEmSJK0KhilJkqQaDFOSJEk1GKYkSZJqMExJkiTVYJiSJEmqwTAlSZJUg8+Z0qAM1RPQh/Sp5z7tXJK06vicKUmSpFXBMCVJklSDYUqSJKkGw9RKRERnRBza4hoOjYjOIerrsoi4ZCj6kiRJlVGtLkCtFxGvBO4DJmamnwlJkgbAkakhEhGjW11DDV8EZre6CEmShiNHIfq2fUTMBHYF7geOzcxZEXEZMBp4CdgfuCYipgBXAm8BxgAPAadl5p0AEXEEcDpwAXAq8ErgWuC4zFxejtkNuBDYGbgXuKO5mIjYEJgGvB8YB8wFjs7MmRExBjirtG0AzAROyMy5vd1cRLwdeBswFXjHIN8jSZJGLEem+nYMcCKwGXAdcGtEjC1tBwK3U4WaKVTv5/XATsDmwLeB70XEuKb+JgJbAjsAbyp9HAwQERsDt5XrbAacDBzXrZ4ZwO7A3sBY4H3Ak6XtfODN5Wci8DTQERHr9nRjJXx9A/gw8Kf+vyWSJKmLI1N9m5GZ9wBExNlU4Wa/0jYzM68p28+X1yubzv1SRJxGFZpuLfteAM4oI1EPRcQPgACuKv0uBc7OzAYwKyJmAIeU648HPgDskpld03IPlrZ1gMOA92bmvLLvJOBZYDfgZz3c21lARxlpe8eA3xlJkmSY6ofOro3MbETEXGBC9zaAiNgAOAfYF9gCWAFsRDVy1WV+15ResbQcQ+l3TglSXZrXMk0qrw/0UOc4YH3gkaZ6l0TEfGAbuoWpiNgTeA/wNz30JUmS+slpvr5N6tqIiDZgW+CxsmtFt2NPAfaimoLbODM3ARawkkfQdzMPmFiu02W7pu3O8rpTD+c+BbzYfHxZXzUeeLSH499FFd7mRsTTwE3AuhHxdES097NeSZJGPEem+jY5Im4Afku1hmkMcAuwTw/HjqUKNM8A65Upvk0GcK2bqRanT42I84E3AJNLn2Tm/Ii4DriwLGafQ7X2isx8KCKuAM6MiD8AC4FzqRbN/7KHa50HND9zag+qNV67lvolSVI/ODLVt4upAs4C4CBg38xc1Mux51GFmMeBh6nWUXX290KZuZBqivCgcr0LgK93O2wy1bf8fgQsphpR2qq0nQwkMIvqW36volpDtbxbH2Tmc5n5WNcP1cgW5fcX+luzJEkjXVuj0ej7KKmbtunLhuSD05h6wFB0Uzq7cej6kiTp5XpdsuPIlCRJUg2GKUmSpBqc5tOgdHR0NNrb/dKfJGnEcJpPkiRpVTBMSZIk1WCYkiRJqsEwJUmSVINhSpIkqQbDlCRJUg0+GkGDMhRPQB+yp5/75HNJ0qrnoxEkSZJWBcOUJElSDYYpSZKkGgxTkiRJNRimJEmSajBM9VNEfCoiOlp07WkRcVcrri1JklZuVKsLWFNFxN3AXZn5eYDM/EJrK5IkSWsiR6b0v0REW0QYtCVJ6gf/w+xBRHwVeBuwR0R8ApgHfBvYMzPfVY7pBC4B9gbeBMwGDgFeD5wJjAO+CxyTmcvKOdsC5wFvLZfqAKZk5uJ+lNUWEV8Ajiq/fz0zP9NU817AOcDOwBPA+Zl5UWl7B9Uo26im46d1u58GcBLwr+Ue3gn8vB91SZI0ojky1YPMPB74MXBmZm6Yma/t5dDDgeOATYHfADdQhZC/Ad4AvBf4AEBErA/8J/AHYHvgdcAE4Mv9LOvtwFxga6Ad+FREvLX0vR1wO/DvwObAEcBZEXFgv2+68iHgIGBD4NcDPFeSpBHJkal6Ls7M/wcQEVdTjUy9OTOXAkvLuqs3AVcD+wFtmXlGOfeFiPg08NOI+HBmLu/jWg9k5r+X7V9ExL1AAD8B/gX4VWZ+s7T/PCIuohrF+u4A7md6Zj5ctvuqR5IkYZiq64mm7eeB5Zn5VLd9G5Xt7YBtI2Jht8Lyt7gAACAASURBVD4awFZUU4n9vRbA0qa+twEe6db+MLB/H3121znA4yVJGvEMU71bMcT9zaEaXXr9EPcL8Cjwnm77ti/7AZYA60bEKzLzxbJv6x76Gep7liRprWeY6t2TwI5D2N/NwOcj4lPAV6gCztbAbpl5Q82+vw18OiIOo5pS/DvgaODY0v7f5XpHRcTXgbcABwC/qnldSZJGPBeg9+58ICJiYUT8vm5nmfk81Tf/XgfcDywCfgDsOgR9z6YamToeeAb4FnBGZl5b2hcDRwJTynVPBC6ve11JkgRtjUaj1TVoGGqbvqz2B6cx9YChKAUaNw5NP5Ik9a6t1wbDlAajo6Oj0d7e3uoyJElaXXoNU66ZWgNExNuA23pp/oJ/ykaSpDWXYWoNkJk/pnpQpiRJGmZcgC5JklSDYUqSJKkGw5QkSVINhilJkqQaDFOSJEk1+JwpDUrdh3bWfmCnD+qUJK1evT5nypEpSZKkGgxTkiRJNRimJEmSalhjw1REdEbEoa2uYySJiLsiYlqr65AkaTjp88/JRMTdwF2Z+flVX06vNWwG3AjsDKwPPAV8E/i3zOxzIXREjAVOB/4J2BpYCNwLnJeZP+jH+UcAp2fmjoO9h1aLiEnAbGCbzHysxeVIkrTWWGNHprpZChwLvDozxwLvAg4BPtzXiRGxITATeBvwQWBTYAfgYqDmV8pWr4gY3eoaJEnSyw36Dx1HxObAOcA+VKNFPwQ+lpl/jIjjgQ9l5t82Hb8d8BCwQ2Z2RsS2wHnAW8shHcCUzFzc/VqZ+SLw+267VwCv7UepJwGvBnbKzGeb9t9UfoiICcAlwBuB9YD7gJMy856I2AP4d2C9iFhSzt0vM++OiF2Ac8t5zwNXAWdk5p9Kv7sDFwKvAX4D3AFMzsxJTe/h+cC7qb5y+R/AyV11RkQncCnwTmA34KiIuBR4S2b+uutGIuK/gDsz88x+vB9d57QBnwA+CowBLmclX/uUJEk9G9TIVPmP+EagAewCTAQWA1eXQ64C/ioidm067Qjg7hKk1gf+E/gDsD3wOmAC8OU+rntzRLwAPAJsBFzUj3LfA9zWLUh1tw5V6JkIbAX8Crg+IkZn5s+AY4BHMnPD8nN3RIwHfgRcTzV1uAdVKPpkqXVj4FbgO8BmwMeAo7td9yqqkbLXAX8FbAF8q9sxHwZOATakes+/CxzV9J68plz70n68F80OBU4G9i/3/DTw9gH2IUnSiDfYab43lp+PZuaizHweOBX4+4iYkJkLqEZ9joQ/h6/D+ct/+PsBbZl5Rma+UI7/NHBIRKzb20Uzcz+qULEHVeh4uh+1jgPmreyAzJybmd/PzOcz8wWq9VXbAjut5LTDgN9k5kWZ+VJmzgPOKvsB2oElwPTM/FMZSfpz4ImIrYH/A5ySmQvKe3AK8J6IeFXTdb6Rmb/OzEap7WLggyWQAnwIuL1cfyAOAy7KzHsy86VS+5MD7EOSpBFvsNN82wGvAP4YEc37/4cqhDxGtUD8yoiYSrVeaROqUZyu87eNiIXd+m1QjZL0Ggwycznw84h4O/A14F/6qPUpqmm+XkXEFlRTju8oda4oTeNWctp2wFu73UMb0BUGXw3M7bZAfk7T9jbldXbTvoeb2p4o253NF83MmRExDzggIr5DFVI/spI6ezOhue/MXBERc3o/XJIk9WSwYWoO1aLwzTJzRS/H3EEVrvaj+hbdd8rIStf5D2Tm6wd5fahqX9nIUZdbgZMiYtMy+tOTs4BXAbtn5hMRsRHwHH9ZQ9TTPc6h+pbjvr30OY8qMLY1Baptm9ofLa+TqNaSQTXl2dzW27UvphqRWgIsB27ppYaVmVeuDfx59HDiIPqRJGlE62+YGtU0rQTwO6pHC3w5IqZl5jMRMQ7YOzO/A38e6bgCOAF4E9Ui6i43A5+PiE8BX6EKBVsDu2XmDd0vHhFvBl4J/BR4iWrR+olUoaIvXwY+ANwcESdSLQRfh+obgftm5nHAWKoF5AvKt//O7tbHk8D4iBibmc+VfVcAUyJiMtVasZeowslrMvP2co8XAKdExAVU66KOpAo/ZObjEXEHcG5EHE4V3M6lWt/1BCt3BVUA/AzwzTJaN1DfAs6JiBuA3wIfpxoVlCRJA9DfNVOfAV5o+lkKHFzOvyciFgO/oJoma/ZNYC9gdmb+smtnWWO1N1XAuB9YBPwA2JWerUf1zcH5wAKqhecXANP6Krx8O3BP4CfANeVaj1A9auHapvsbDzxD9U2+n1JCT/GfwJ3A7IhYGBF7ZeaTVAHxfVTTZQuAGyijS5m5ENiX6hEOC6imJC8DXmzq91Cqhfv3l5+F/GXN1cruaSFwHfA3wIy+ju/FFVRBtgP4I9X9/9cg+5IkacRqazT6fOalhkhEnAW8MTP3GYK+plE9IqF2X4PRNn1ZrQ9OY2rNR3w1bqx3viRJA9Pr44MG/Zwp9S0i3k01JfpHqqnJj1BNp9Xtd0uqRyYMZuG5JEkaQsM+TEXE24Dbemn+QmZ+YXXW080bqNYmjQUeB75E9XDMQYuI86ieV/WtzLylW9uSns/ix5n5j3WuK0mSeuY0nwalo6Oj0d7e3uoyJElaXXqd5hsuf5tPkiRpjWSYkiRJqsEwJUmSVINhSpIkqQbDlCRJUg2GKUmSpBp8NIIGpaVPQPfp55Kk1c9HI0iSJK0KhilJkqQaDFOSJEk1GKYkSZJqMEytRER0RsShLa7h0IjoHKK+LouIS4aiL0mSVBnV6gLUOhFxN7AH8Kem3Qdn5s2tqUiSpOHHMDVEImJ0Zv6p7yPXOGdm5udbXYQkScOVYapv20fETGBX4H7g2MycFRGXAaOBl4D9gWsiYgpwJfAWYAzwEHBaZt4JEBFHAKcDFwCnAq8ErgWOy8zl5ZjdgAuBnYF7gTuai4mIDYFpwPuBccBc4OjMnBkRY4CzStsGwEzghMycO+TviiRJAlwz1R/HACcCmwHXAbdGxNjSdiBwO1WomUL1fl4P7ARsDnwb+F5EjGvqbyKwJbAD8KbSx8EAEbExcFu5zmbAycBx3eqZAewO7A2MBd4HPFnazgfeXH4mAk8DHRGx7kru76SIeDYifh8Rn4yI0f17WyRJEjgy1R8zMvMegIg4myrc7FfaZmbmNWX7+fJ6ZdO5X4qI06hC061l3wvAGWUk6qGI+AEQwFWl36XA2ZnZAGZFxAzgkHL98cAHgF0yc3bp78HStg5wGPDezJxX9p0EPAvsBvysh3v7JNVo23OlxquoAtonB/QOSZI0ghmm+tbZtZGZjYiYC0zo3gYQERsA5wD7AlsAK4CNqEauuszvmtIrlpZjKP3OKUGqy+ym7Unl9YEe6hwHrA880lTvkoiYD2xDD2EqM5v3/TwizgC+iGFKkqR+c5qvb5O6NiKiDdgWeKzsWtHt2FOAvaim4DbOzE2ABazk7/l0Mw+YWK7TZbum7c7yulMP5z4FvNh8fFlfNR54tJ/XXzGAWiVJEo5M9cfkiLgB+C3VGqYxwC3APj0cO5Yq0DwDrFem+DYZwLVuplqcPjUizgfeAEwufZKZ8yPiOuDCsph9DtXaKzLzoYi4AjgzIv4ALATOpZrG+2X3C0XEJsCewN1Uo2O7Ui1sv6b7sZIkqXeOTPXtYqqAswA4CNg3Mxf1cux5VCHmceBhqnVUnf29UGYupJoiPKhc7wLg690Om0z1Lb8fAYuBm4CtStvJQAKzqL7l9yqqNVTL+d9GU32zcB7VmqlrgKtxik+SpAFpazQafR8lddM2fVmtD05j6gE1Tr6xzqUlSRqMXpfBODIlSZJUg2FKkiSpBqf5NCgdHR2N9vb2VpchSdLq4jSfJEnSqmCYkiRJqsEwJUmSVINhSpIkqQbDlCRJUg2GKUmSpBp8NIIGpc4T0H36uSRpGPLRCJIkSauCYUqSJKkGw5QkSVINhilJkqQaRrW6ALVWRKwLfBE4AlgfuAM4OjOfbmVdkiQNF45M6RPA/sDuwISy71utK0eSpOHFMKWPAGdn5iOZuQg4FfiHiJjU2rIkSRoeDFMjWERsDGwL3NO1LzMfBp4D/rpVdUmSNJwYpka2seV1Ubf9C5vaJEnSShimRrbF5XXjbvs3oRqdkiRJfTBMjWCZuRCYC/xd176I2J5qVOq+VtUlSdJw4qMRdDFwWkT8EHgGOBv4j8zsbGlVkiQNE4YpfRHYFJgFvAK4Ezi0pRVJkjSMGKZGuMxcDny8/EiSpAFyzZQkSVINhilJkqQa2hqNRqtr0DDU0dHRaG9vb3UZkiStLm29NTgyJUmSVINhSpIkqQbDlCRJUg2GKUmSpBoMU5IkSTUYpiRJkmowTEmSJNXgc6Y0KG3Tlw36g9OYesDgL9y4cfDnSpI0eD5nSpIkaVUwTEmSJNVgmJIkSaphRIepiOiMiENbXMOhEdE5RH1dFhGXDEVfkiSpf0a1ugCtOhFxAnAI8Abg8czcsVv7x4CPAeOB5UACUzPzvtVdqyRJw9WIHpkaiIgY3eoaBuFx4Bzg33ppvxV4S2ZuArwKuAO4NSJ6/caCJEl6OUemYPuImAnsCtwPHJuZsyLiMmA08BKwP3BNREwBrgTeAowBHgJOy8w7ASLiCOB04ALgVOCVwLXAcZm5vByzG3AhsDNwL1WA+bOI2BCYBrwfGAfMBY7OzJkRMQY4q7RtAMwETsjMuT3dWGZe11RXT+0Pd9u1HHg1sBHwXO9vmSRJ6uLIFBwDnAhsBlxHNTIztrQdCNxOFWqmUL1f1wM7AZsD3wa+FxHjmvqbCGwJ7AC8qfRxMEBEbAzcVq6zGXAycFy3emYAuwN7A2OB9wFPlrbzgTeXn4nA00BHRKw72JuPiD0jYiHwP8B5wJcy0yAlSVI/OTIFMzLzHoCIOJsq3OxX2mZm5jVl+/nyemXTuV+KiNOoQtOtZd8LwBllJOqhiPgBEMBVpd+lwNmZ2QBmRcQMqnVNRMR44APALpk5u/T3YGlbBzgMeG9mziv7TgKeBXYDfjaYm8/MmcAmEbEJcDjw2GD6kSRppHJkCjq7NkrAmQtM6N4GEBEbRMRXIuKRiHiujOhsSjVy1WV+15ResZRq2ozS75xynS6zm7YnldcHeqhzHLA+8EhTvUuA+cA2K7m/fsnMhcBXgBkR8Vd1+5MkaaQwTP0lwFAWXm/LX0ZnVnQ79hRgL6opuI3Lwu0FrOQR893MAyZ2W+C9XdN2Z3ndqYdznwJebD6+rK8aDzzaz+v3ZR1gPaopSkmS1A9O88HkiLgB+C3VGqYxwC3APj0cO5Yq0DwDrFem+DYZwLVuplqcPjUizqd6ZMHk0ieZOT8irgMuLIvG51CCTWY+FBFXAGdGxB+AhcC5VIvmf9nTxSJiFNW/8WigLSLWL339T2k/utzrPKo1YJ+nWjv1iwHckyRJI5ojU3AxVcBZABwE7JuZi3o59jyqEPM48DDVOqrO/l6oTKXtW66zoFz3690Om0z1Lb8fAYuBm4CtStvJVM+CmkU1HfkqqjVUy+nZ6VRruC4Gti/bLzS170YVxJYAvwO2Bt6VmU/1954kSRrp2hqNRt9HSd20TV826A9OY+oBg79w48bBnytJ0uD1uqTHkSlJkqQaDFOSJEk1OM2nQeno6Gi0t7e3ugxJklYXp/kkSZJWBcOUJElSDYYpSZKkGgxTkiRJNRimJEmSajBMSZIk1eCjETQoA30C+qCeeu7TziVJaw4fjSBJkrQqGKYkSZJqMExJkiTVYJiSJEmqYVSrC9DqExGfAvbIzB7/qF5ETAAeBbbLzM7VWZskScOVYaqfIuJu4K7M/HyraxmszPxCq2uQJGlt4zTfMBIRo1tdgyRJerkRNzIVERsC04D3A+OAucDRwATgk8B2wFLg+8Apmbk0Ir4KvA3YIyI+AczLzNeW/j4MnAhsAzwCnJaZd5S2ttLnccAY4HLgr4EfZ+a0csxewDnAzsATwPmZeVFpewdwF3Ak8FlgXEScChyTmX/TdE87AP8N7JCZc1Zy79OAPTPzXeX3rYCLgb2AP5Y6JEnSAIzEkakZwO7A3sBY4H3Ak8Ai4IPAJlTB6W3A6QCZeTzwY+DMzNywKUh9BDgNOATYFPi/wPURsWO51r9SBa12YEuqsPT2rkIiYjvgduDfgc2BI4CzIuLApnrXBf4R+NvSx1XADhHxpqZjPkQ1BdlrkOrFVcByYNtS1xEDPF+SpBFvRI1MRcR44APALpk5u+x+sLw+1HToQxFxIXBYH12eAHwuM39Tfr81In4IHAx8vpx/UWb+ulz/S8BHm87/F+BXmfnN8vvPI+Ii4Cjgu03HfSIzFzXdx3eoAtSsiFgXOLzU0m8R8Wrg74EdS9+LIuKzwB0D6UeSpJFuRIUpYFJ5faB7Q0S8GziDarrtFVQjQvP76G874GsRcUHTvlHAY2X71cCfR4sysxERjzYd2zU12OxhYP+m31dQfcOu2UXAXRFxCtUI2yiqacmBmFBem0ezZvd0oCRJ6t1IC1Od5XUn4A9dOyNiPeBG4FTg0sx8ISKOBz7edO6KHvqbA3wmM7/bQxvAPGBi03XaqAJUl0eB93Q7Z3teHp4amfmyv4OXmbMi4mHgQOCfgMsy80+91NCbeeV1IlWAgyocSpKkARhRYSoz50fEdcCFEXEEVRjaAVi//CwoQep1wPHdTn8S2LHbvvOBaRHxIPCb0scbgacz837gW8DZEfE9qvB2ArB10/nfBj4dEYcBVwN/R7UY/th+3M7FwBSqkbSp/Tj+ZTLzsfK4h3Mi4khgA+DTA+1HkqSRbiQuQJ8M3Av8CFgM3ES16PxYqmCxBPgaVbhpdj4QEbEwIn4PkJnfoPoG3DeBBVTfDPw00PUIgytKX7dRfVtuAvBz4MVy/myqkanjgWeowtcZmXltP+7jKqqRpJ9k5oN9HdyLD1JNaT5KtcD+ikH2I0nSiNX2/9u7/zirqnr/46+PMCDIzDD88EcgIKJ2TZJ04c0uKGVZXqFMRfNCRPQ1DbmlJmpg3vFXogLeLH+WSf7WNCEIxbRb99LDylVpChIgDij+4IcwgoT82t8/1hrYHM6ZOTPncA447+fjMY85Z6+91157nb33+Zy11t47SZKm55KicM7tQwi4LvXeZwZrzc3LCOOtJhaaV0vY5C3N2nGS8Wc2fyXJ9OYvIyIisntYroRW1c1XDs65swmtX/sQ7jm1H6GlqlAjgHbAY0XIS0RERFpIwdTu95+E8U0ALwP/7r1fU0iGzrmVwBbgG977TanpIwhX+mVznvf+gULWm/arI55k2LCsj/jL7hK1MomIyIeTuvmkRWbOnJk0K5gSERHZu+Xs5muNA9BFREREikbBlIiIiEgBFEyJiIiIFEDBlIiIiEgBFEyJiIiIFEDBlIiIiEgBdGsEaZHdfgd03f1cRET2LLo1goiIiMjuoGBKREREpAAKpkREREQKoGCqEc65OufcyDKXYaRzrq5IeU1zzv20GHmJiIhIoAcdt3LOua8AE4BDgXXAj7z315W3VCIiInsPtUwViXOuotxlaC7n3FeBm4GLgWrgMOBXZS2UiIjIXkYtU03r65ybCwwAFgDf8t4/75ybBlQAm4AvAY84574L3A98CugILAYu897/BsA5Nxq4ArgFuBTYD3gUGOu93xrnOQ64Dfgo8ALwdLowzrlOQC1wOtAdWAac572f65zrCFwf0zoAc4Fve++XZW6Uc24fYBJwlff+mTh5HfBSAXUlIiLS6qhlqmnnA98BugCPAbOdc1UxbTjwFCGo+S6hPn9JaOHpCjwEPO6c657KrzdwAKFbbWDM4ysAzrlq4Mm4ni7ARcDYjPLcDfwrcBJQBZwGvB3TbgY+Gf96A6uAmc65Nlm263DgI0An59wC59wK59ws51y/5lSOiIhIa6eWqabd7b3/C4Bz7gZCcDM0ps313j8SX2+I/+9PLXuTc+4yQtA0O077J3BlbIla7Jx7FnDAAzHf94EbvPcJ8Lxz7m5gRFz//sBZwFHe+9difoti2j7AKOCL3vvlcdqFwLvAccBzGdvVLf7/GnAK8A4wmRB89ffeb2leNYmIiLROCqaaVtfwwnufOOeWAT0z0wCccx2AG4FTCcHKNqCS0HLVYEVDl170fpyHmO/SGEg1eC31uk/8vzBLObsD+wJLUuVd75xbARzMrsHUuvj/hw2BmXNuArCG0Go1P8s6REREJIO6+ZrWp+GFc86AXsAbcdK2jHkvBk4kdMFVe+87E4KTnLegz7Ac6B3X0+CQ1Ou6+P+wLMuuBD5Izx/HV+0PvJ5l/n8QWsmyPRZGzxgSERHJk1qmmjbGOfcEYWD2RYSB5b8GTs4ybxUhoFkNtItdfJ2bsa5ZhMHp451zNwP9gTExT7z3K5xzjwG3xcHsSwljr/DeL3bO3Qtc45ybD6wFphAGzf85c0Xe+43OuXuA7zjnngZWANcA88je8iUiIiJZqGWqaXcRApw1wNnAqd77+hzzTiUEMW8CrxLGUdXluyLv/VpCF+HZcX23ALdnzDaGcJXf7wlddTOAA2PaRYAHnidc5XcQYQzVVrK7mHDF34vEVjFgWCPzi4iISAZLEvXoSPPZ5C3N2nGS8Wc2bwXJ9ObNLyIisnvlHLKjlikRERGRAiiYEhERESmAuvmkRWbOnJkMGzas3MUQEREpFXXziYiIiOwOCqZERERECqBgSkRERKQACqZERERECqBgSkRERKQACqZERERECqBbI0iL7NY7oOvu5yIisufRrRFEREREdgcFUyIiIiIFUDAlIiIiUgAFUyIiIiIFUDAlIiIiUoC25S6AlJdz7kDgh8BnCPvD34CLvPcvlrVgIiIiewm1TMltQBfgCOAAwAOznHM5LwEVERGRHRRMST/gF977d733m4C7gZ5A1/IWS0REZO+gbj65CRjpnPslsB74JjDXe7+qvMUSERHZO6hlSv4AtAFWEoKp04Fzy1oiERGRvYiCqVbMObcP8AywEKgGOgLXAf/nnDugnGUTERHZWyiYat26AIcAP/Lev+e93+S9/ylhv/hkeYsmIiKyd9CYqVbMe7/KObcQGOucuxz4ABgFVAIvlbVwIiIiewkFU3IaYRD6UqACWAwM994vKWupRERE9hIKplo57/0rwNByl0NERGRvpTFTIiIiIgVQMCUiIiJSAEuSpNxlkL3QzJkzk2HDhpW7GCIiIqWS8zFrapkSERERKYCCKREREZECKJgSERERKYCCKREREZECKJgSERERKYCCKREREZEC6NYI0iI2eUujO04y/symM0mmF6s4IiIiu5tujSAiIiKyOyiYEhERESmAgikRERGRArTqYMo5V+ecG1nmMox0ztUVKa9pzrmfFiMvERERyU/bchdAdh/n3LeBEUB/4E3vfb+M9JOACcAngBrgYO/9GyUvqIiIyF6sVbdMNYdzrqLcZWiBN4EbgetypL8P3At8tWQlEhER+ZBRyxT0dc7NBQYAC4Bvee+fd85NAyqATcCXgEecc98F7gc+BXQEFgOXee9/A+CcGw1cAdwCXArsBzwKjPXeb43zHAfcBnwUeAF4Ol0Y51wnoBY4HegOLAPO897Pdc51BK6PaR2AucC3vffLsm2Y9/6xVLmypf8R+KNzrk++lSUiIiI7U8sUnA98B+gCPAbMds5VxbThwFOEoOa7hPr6JXAY0BV4CHjcOdc9lV9v4ADgUGBgzOMrAM65auDJuJ4uwEXA2Izy3A38K3ASUAWcBrwd024GPhn/egOrgJnOuTYF1oGIiIi0kFqm4G7v/V8AnHM3EIKboTFtrvf+kfh6Q/x/f2rZm5xzlxGCptlx2j+BK2NL1GLn3LOAAx6I+b4P3OC9T4DnnXN3E8Y14ZzbHzgLOMp7/1rMb1FM2wcYBXzRe788TrsQeBc4DniuGJUhIiIizaNgCuoaXnjvE+fcMqBnZhqAc64DYQzSqUA3YBtQSWi5arCioUsvej/OQ8x3aQykGryWet0n/l+YpZzdgX2BJanyrnfOrQAORsGUiIhIWaibb0cAg3POgF5AwxVt2zLmvRg4kdAFV+297wysoZFbzGdYDvSO62lwSOp1Xfx/WJZlVwIfpOeP46v2B17Pc/0iIiJSZGqZgjHOuSeAlwhjmDoCvwZOzjJvFSGgWQ20i118nZuxrlmEwenjnXM3E25ZMCbmifd+hXPuMeC2OGh8KWHsFd77xc65e4FrnHPzgbXAFMKg+T9nW5lzri3hM64AzDm3b8xrY0zfB2gHtI+LtI/zbPLeZwaSIiIikoVapuAuQoCzBjgbONV7X59j3qmEIOZN4FXCOKq6fFfkvV9L6CI8O67vFuD2jNnGEK7y+z2wDpgBHBjTLgI88DzhKr+DCGOotpLdFYQxXHcBfePrf6bST4jvF8T3i+P7E/LdJhERkdbOkiRpei6RDDZ5S6M7TjL+zKYzSaYXqzgiIiK7W84hPWqZEhERESmAgikREREpqdraWkaOLOujcYtKA9ClRX51xJMMGzYs9wyXqAtPRKSUbPKW3Zp/cknzQoYHH3yQqVOnsmDBAiorKxkwYAATJ05k0KBBu6mEudXV1fH1r3+dP/3pT/Tq1Ysf//jHfPazny1a/mqZEhERkaKaOnUqF154IRMmTOCdd95h2bJljB07lhkzZpSlPOeccw6f+MQnWL16Nddddx1nnnkmK1euLFr+CqZERESkaOrr67nyyiu59dZbOf3009lvv/2oqKhg2LBh3HTTTVmXGT58OAceeCDV1dWccMIJzJs3b3va7NmzOfLII6msrKRHjx5MnjwZgFWrVjF06FA6d+5Mly5dGDx4MNu27XpXn4ULF/LXv/6Vq666ig4dOnDGGWfQv39/Hn/88aJts4IpERERKZrnnnuOjRs38uUvfznvZU455RQWLVrEihUrOOaYYxgxYsT2tG984xvceeedrFu3jpdffpnPfOYzAEyZMoWePXuycuVK3nnnDQpMrAAAHCFJREFUHX7wgx9gtusFd/PmzaNv375UVlZun3b00UfvFLAVSsGUiIiIFM3q1avp1q0bbdvmP8ZqzJgxVFZW0r59e2pra3nxxReprw+3fKyoqGD+/Pm899571NTUcMwxx2yf/tZbb7F06VIqKioYPHhw1mBq/fr1VFdX7zSturqadevWFbCVO1MwJSIiIkXTtWtXVq1axZYt+Q2I37p1K5dffjmHHnooVVVV9OnTBwjdeACPP/44s2fPpnfv3px44ok891x4FO348ePp168fJ598Mn379mXSpElZ8+/UqRPvvffeTtPee++9nVqqCqVgSkRERIrm+OOPZ99992X69Pyu6n7wwQeZMWMGzzzzDPX19dTV1QHQcFPxgQMHMmPGDFasWMFpp53GWWedBUBlZSVTpkxhyZIlzJw5k6lTp/Lss8/ukv/HPvYxlixZslNL1IsvvsjHPvaxArd0BwVTIiIiUjTV1dVcffXVXHDBBUyfPp0NGzawefNmnnzySS699NJd5l+3bh3t27ena9eubNiwgQkTJmxP27RpEw888AD19fVUVFRQVVVFmzZtAJg1axaLFy8mSZLt0xvS0g4//HAGDBjAVVddxcaNG3niiSf4+9//zhlnnFG0bdZ9pqRFvviPU+AfuZtwm3ycjB4lIyJSVM29D9TudPHFF3PAAQdw7bXXMmLECCorKzn22GOZOHHiLvOOGjWKOXPm0KNHD7p06cI111zD7bfveGztfffdx7hx49i6dStHHHEE999/PwCLFi1i3LhxrFy5kpqaGsaOHcuQIUOylufhhx9m9OjR1NTU0KtXLx577DG6d+9etO3Vs/mkRQp+Np+CKRER2bvo2XwiIiIiu4OCKREREZECKJhqhHOuzjlX1icxOudGOufqipTXNOfcT4uRl4iIiAR7zmg1KTnnXG/gh8AgQl/wI8BF3vsPylowERGRvYhaporEOVdR7jI0h3OuDTATeB3oCRwNHA9MKWe5RERE9jZqmWpaX+fcXGAAsAD4lvf+eefcNKAC2AR8CXjEOfdd4H7gU0BHYDFwmff+NwDOudHAFcAtwKXAfsCjwFjv/dY4z3HAbcBHgReAp9OFcc51AmqB04HuwDLgPO/9XOdcR+D6mNYBmAt823u/LMt2HQH0BwZ77zcCbzjn/hu4zTl3SZwmIiIiTVDLVNPOB74DdAEeA2Y756pi2nDgKUJQ811Cff4SOAzoCjwEPO6cS9/MojdwAHAoMDDm8RUA51w18GRcTxfgImBsRnnuBv4VOAmoAk4D3o5pNwOfjH+9gVXAzNgKlanhs7eMaR2BwxuvEhEREWmglqmm3e29/wuAc+4GQnAzNKbN9d4/El9viP/vTy17k3PuMkLQNDtO+ydwZWyJWuycexZwwAMx3/eBG7z3CfC8c+5uYERc//7AWcBR3vvXYn6LYto+wCjgi9775XHahcC7wHHAcxnbtYDQcvYD59wlhIDwOzGtChEREcmLWqaaVtfwIgY4ywhjjHZKA3DOdXDO/cg5t8Q5955zbi1QQwhUGqxo6NKL3gcanrbYE1ga19PgtdTrPvH/wizl7A7sCyxJlXc9sAI4OHNm7/0WYBhwSNyOOYSADkKLloiIyG5RW1vLyJFlvVi+qNQy1bQ+DS+ccwb0At4AjgS2Zcx7MXAioQuuznufOOdW0chdUzMsB3o75ywVUB2SSq+L/w8D5mcsuxL4IM7/aixvJ2B/wiDzXXjvFwCnpLbvAuBNsgdrIiKyJ7PTdm/+zXxyxYMPPsjUqVNZsGABlZWVDBgwgIkTJzJo0KDdVMDcvv/97zN9+nReeeUVrrjiCmpra4uav4Kppo1xzj0BvEQYw9QR+DVwcpZ5qwgBzWqgXezi69yMdc0iDE4f75y7mTBAfEzME+/9CufcY4RB4qOBpYSxV3jvFzvn7gWucc7NB9YSrsxbAPw528qcc/0JLV8bgSHAlYQB85lBooiISN6mTp3KpEmTuOOOO/j85z9Pu3bteOqpp5gxY0ZZgql+/fpx4403cscdd+yW/NXN17S7CAHOGuBs4FTvfX2OeacSgpg3Ca1DG8joCmyM934tcGpcz5q43tszZhtDuMrv98A6YAZwYEy7CPDA84TuyIMIY6i2kt3phGDqPcLg9Yu899PyLa+IiEim+vp6rrzySm699VZOP/109ttvPyoqKhg2bBg33XRT1mWGDx/OgQceSHV1NSeccALz5s3bnjZ79myOPPJIKisr6dGjB5MnTwZg1apVDB06lM6dO9OlSxcGDx7Mtm3Z2wK+9rWvccopp1BZWZk1vVB60LG0iB50LCKyh9lDuvmeeuophg4dysaNG2nbNnsHWG1tLYsXL+b++8M1Wz/72c8YPnw47dq147LLLuN3v/sdL7zwAgAHHXQQjz76KIMHD2bNmjW89tprHHPMMXzve99jzZo1/OhHPwLgj3/8I4MGDcIs98iakSNH0q9fv5Z28+XMWN18IiIiUjSrV6+mW7duOQOpbMaMGbP9dW1tLTU1NdTX11NdXU1FRQXz58/n6KOPpqamhpqaGgAqKip46623WLp0Kf369WPw4MFF35Z8qZtPREREiqZr166sWrWKLVu25DX/1q1bufzyyzn00EOpqqqiT58+QOjGA3j88ceZPXs2vXv35sQTT+S558KdfsaPH0+/fv04+eST6du3L5MmTdot25MPtUxJi/zqiCcZNmxY7hkuUTeeiEhrdPzxx7Pvvvsyffp0zjyziSEfhKv+ZsyYwTPPPEOfPn2or6+npqaGhmFIAwcOZMaMGWzevJkf//jHnHXWWbz++utUVlYyZcoUpkyZwrx58/j0pz/NwIEDOemkk3b3Ju5CLVMiIiJSNNXV1Vx99dVccMEFTJ8+nQ0bNrB582aefPJJLr300l3mX7duHe3bt6dr165s2LCBCRMmbE/btGkTDzzwAPX19VRUVFBVVUWbNuGhHrNmzWLx4sUkSbJ9ekNaps2bN7Nx40a2bdvGli1b2LhxI1u35ro2q/nUMiUiIvJhsAdd2HPxxRdzwAEHcO211zJixAgqKys59thjmThx4i7zjho1ijlz5tCjRw+6dOnCNddcw+2377iQ/b777mPcuHFs3bqVI444Yvug9UWLFjFu3DhWrlxJTU0NY8eOZciQIVnLc+655/Lzn/98+/vrrruOe+65h9GjRxdle3U1n7TIzJkzk0a7+URERD5ccl7Np24+ERERkQIomBIREREpgIIpERERkQIomBIREREpgIIpERERkQIomBIREREpgIIpERERkQIomBIREREpgIIpERERkQIomBIREREpgIIpERERkQIomBIREREpgB50LC3Svn37lzdt2rSx3OXYk7Rt27bbli1bVpW7HHsS1Ul2qpddqU52pTrJroz1sipJki9kS2hb6pLIh0P//v03eu9ducuxJ3HOedXJzlQn2aledqU62ZXqJLs9sV7UzSciIiJSAAVTIiIiIgVQMCUtdVe5C7AHUp3sSnWSneplV6qTXalOstvj6kUD0EVEREQKoJYpERERkQIomBIREREpgG6NIDk55w4Hfg50BVYDo7z3izLmaQPcAnwBSIBJ3vuflrqspZJnnXwf+AqwJf5N8N7PKXVZSymfeknNewTwN+A27/0lpStlaeVbJ865s4DvA0Y4hj7rvX+nlGUtlTyPn/2Be4CDgXbAb4Fve++3lLi4JeGcmwycAfQB+nvvX84yT2s7z+ZTJ3vUeVYtU9KYO4BbvfeHA7cCd2aZZwTQDzgMOB6odc71KVkJSy+fOvkzMNB7fzQwBnjEOdehhGUsh3zqpeFL4U5gegnLVi5N1olzzgG1wOe890cBg4D6UhayxPLZTyYAr3jvPw70B44FTi9dEUtuOnACsLSReVrbeTafOtmjzrMKpiSr+OvwGOChOOkh4BjnXPeMWc8GfuK93+a9X0k4CIaXrqSlk2+deO/neO83xLd/J7Q4dC1ZQUusGfsKwOXALGBhiYpXFs2ok4uAyd77twG89/Xe+w/lkwWaUScJUOmc2wdoT2idWl6ygpaY936u9/71JmZrNedZyK9O9rTzrIIpyeVgYLn3fitA/P9mnJ7Wi51/PSzLMs+HRb51kjYKeNV7/0YJylcuedWLc+7jwOeBm0tewtLLd185EujrnPtf59xfnXNXOOesxGUtlXzr5BrgcOAt4G1gjvf+D6Us6B6oNZ1nW6Ls51kFUyK7iXPuRMIXwznlLku5OecqgJ8A5zd8mQoQxq1+HPgccCJwCvDVspao/IYTWhoOAnoAJzjnzixvkWRPtaecZxVMSS6vAz3iGJeGsS4fidPTlgG9U+97ZZnnwyLfOsE5dzxwP3Ca9/4fJS1l6eVTLwcBhwKznXN1wIXAuc65Pe7me0WS776yFHjMe/+B934dMAM4rqQlLZ186+Q/gQdil1Y9oU4+XdKS7nla03k2b3vSeVbBlGTlvV8BvMCOaP8c4G+xvz7tF4QvxX3i2IfTgMdLV9LSybdOnHMDgUeAM733fy1tKUsvn3rx3i/z3nfz3vfx3vcB/pswBuSbJS9wCTTj+HkQONk5Z7H17iTgxdKVtHSaUSevEa5awznXDvgssMvVXK1MqznP5mtPO88qmJLGnA/8p3NuIeHX4vkAzrnZ8SokgPuAJcAi4I/A1d77JeUobInkUye3AR2AO51zL8S//uUpbsnkUy+tTT518jCwAphPCDTmAXeXoaylkk+dXAgMds69RKiThYQu4g8l59wtzrk3gJ7AM865eXF6qz3P5lkne9R5Vo+TERERESmAWqZERERECqBgSkRERKQACqZERERECqBgSkRERKQACqZERERECqBgSloFM/u8mf1f6v0QM6srY5FKxsymmVnRnjBvZn3MLEm9725mS82sWx7Lnm9m9xWrLHsDMxtsZmvLXY7WyMxGNuc4L/axIo3bXcdGCz73G8zsmkLWqWBKPvTMzAjPg/uvJub7lpm9bGbvmdkaM/NmdnYqvc7MRmZZbpfpFiyMeXXKSBtiZomZrY9/b5rZPWbWpbAtLY8kSVYSbj7ZVP3uB1wN1JagWHuMJEn+L0mSzuUuRy5mVmtmz5S7HK3B7qprM/udmV1R7Hx3t8xjo4z74iTgAjPr0dIMFExJa3Ay4cnz/5NrBjM7hxAMfAOoJjzm4iJgTQvX+WmgL7CN7M+M2pokSackSToBg4DjCXcF31v9DPi6mVU1Ms9I4KUkSV4tUZl2YmZtzEznPBHZSZIka4AngfNamodOLFJUsZXmCjP7n9jq8pKZfdzMzjGzxWZWb2Y/NbO2qWV6mdljZvZW/LvLzCpT6T8wsyUxv1fN7MJUWp/YyvNVM5tvZuvM7GkzOyhVrNOAZ5LG71D7KeB/kyT5UxL8M/5qerqFVXEe8BThzsWNHqBJkiwBZgGfyEwzs7axTr6UMf3nZvaz+PokM/tTbE1baWYPm9n+udYX62tQ6v0QM9uSsc4JsWVtrZn9wcyObWIbFgGrCI/+yOU04DcZZfmOmS2In9syM7vezNrEtMlm9kTG/J+O8+4X3x9lZnPMbFVq+YqY1rBvfMPM5gMbgP3N7Ctm9mJsNXzLzO5syC8ud6CZzYz76sK4fGJmfVLznBtbMevN7G9mdnKujc5Sv9PM7D4z+1ms3+Xx+BhgZs/H7fsfM/tIapk6M7vSzObG48Cb2cBUeqP7gJlVxM/0HzH/V83sDAstrxOAIbajpbRvju04Ma6jPn5m56XShpjZFjM7O+Zdb2aPpo/jLPm15FzxcTP7bdzOJXH5Nqn042LdrDezuYQfNOl1doz71Wtm9q6ZPWVm/XKVMUuZu5rZvXG/edvCcdgllb5TK3VqH+yZq67NbHTc3stivivMbEqW/bhnKt/RZrY4vv4xMBj4fswz6zPqLLT6PGuhS2ulma02s4vNrHes03Vm9hcz+5fUMgUdK6l9/SepfX2X/Sa+brR+MrZlp+7YIn3uvyGco1omSRL96a9of0Ad4ZEH/wJUEB5C+SpwF7Af4QGdK4D/iPPvCywmdP90AGqA2cDPUnmOJLQUGfAZ4J/A52NaHyAhBCPdgCrgD8BPUsv/Cfh2RjmHAHWp98OBjcC1hOejdc6xbSObmg50Bz4ATgcGxPIdm7HuLan3/YB/pLc5I/8bgemp952A9cDg+H4QMBBoCxwI/C/wUGr+acBPU+8TYFAj5flBrLO+QBtCa90qoCZd51nKORO4tpF94x3gixnTzgAOiZ/tJ+I858W0I4FNQPfU/D8H7o6v9wdWE4LVdkAPwANXZuwbz8Z6aRe35xTgY4Qfk/0Ij3K5PrWOZwnPPauK6/hdzKdPTP8mYZ89Oubx7/Hz6JdjuzPrdxphHz41Ln9+XP5XhMdndAR+C9yVsY+9CRwbt+NyYCVQlec+cEPczo/Huu4JfDym1RJ+bDR2XB8Sy/z1uI5PAu8Cw1PbmBAehdMJOIBwHphYxHNFddw/vg+0j8stAcan0lfHumkX6+Ntdj7OHyScKw6I81wFLAAqsh0rWcr8FGE/r4l/vwZ+3ci5oE+sl5656hoYDWwGbiWcAw8lPELne9nySC2zOPX+d8AVTXyGtXE9/48dx8FW4JmMz+Dp1DKFHivTCPvNF2Mep8cy9M5xbOSqn8UZ07Z/TsX43OM8xxJ6Eto1Vo8567clC+lPf7n+4slkfOr9v8eDK/2F+Chwc3x9JvBqRh7HEoKRNjnW8RhwY3zdcKIZmEq/APhb6v1CYHRGHkPSB1ucNhT4JeGEvZXQLXhUxra9D6zN+NvGzifQSwlfAg0n6L8Cd2asO4nLriE82PUOsgRwcf5/IQQV+8f3Y4CFjXwGQ4EVqffbTzzxfc5givBFuw44ISPPlxq2kdzB1APAbY2UaxMwpIn9ZzLwaOr9n4CL4utKQtDxb/H9JcBvM5Y/g3jiTe0bJzSxznHAn+PrnnGZvqn0k9j5C+JlYFRGHjPJ8WVG9mAq/QXcMeY/PDVtLDvvw3XANan3BiwjBhqN7QNx3vXAqTnmraXpYGoC8IeMadcDczL26fRxfhPwRCN51tG8c8V/AK8TH4MWp50H/CO+HhHrJJ1+HfE4J/zYSoBeqfR9gHri8UAjwRThB10CHJaadkScdlBqm1oSTH0AdExN+3/EYzwzj9QyLQmm5mVMW5HlM1hTxGNlGql9PU5bCXwpx7GRq34aC6YK/tzjtMPifPs3Vo+5/rY3n4oU0Vup1xsI44NWZkxraP4/BOhlu17RkRB+YS83s28D5xIOXiP8enuwkXW+n8ofQsDS2FiesMIkmUX49YKZfZTwIM1ZZnZIEo82QqvJ/enlLHXViJlZLOv9SZJsjpPvBiaZ2XeTJFkfp21N8hyUnCTJK2b2V0IL3VRC68A9qXUeS2hNOprwxWyE1oGW6BaXnWmpK/YIv1p7Zl9kuypCYJjLLp+DhbFqFxNawdoSfjX+MTXLPYTA4mbgLGB5kiR/iGmHAP+Wse8Y4Vd3Wl3GOj8HXAl8lNDC0YbwpQKhdQvCybnB0oz8DgFuNbNbUtPaAm+Qv+37a5IkG8Jus8txk9lFVpdaJjGzZcTPpIl9oDuhpWdhM8qX6WBCK1Daq0C6+znzOM88DrNpzrniYMIXZHq/fDVOh1AXSzPS0/vjIfH/32N9N6hI5dGYhnnSeb6aSnuLlluRJMmG1Ps6mj7eWiKzjBtoZL8rwrGSbZ357BfNUazPvYodP3KbTWOmpNyWEn6Bdc742zdJkuVm9m+ELorzgG4xAJlJ+LLI198IXUZ5S5JkAeELvDehOT9fJxGaw8fEMRVvE5qUOxF+WbfUPcDo2M//SeDeVNrDhNavw5MkqSL7gPe09wlfrg0+knq9KqZ/NuPz2C9JkklN5HsUoa5z2elzMLODCd0K1xJ+2VcTujrSn+3DwGFmdgzhF+o9qbSlhF+x6XJWJ2FQf9q21DrbAdNjvr1ifV2WWufy+L9Xavn064b1jslYb6ckSb7VyLYXQ5+GFzFo78WOAK6xfWAl4TM9LEe+23JMT3udHV9KDfrG6aXyOtDbdv5GTJdheZb0dJkbvugPy/jsOiZJ8lCe64fU58COsTkNaevJfWxB7rre38w6pt73Ycdn2/ADrCX5tliRjpXmyrYdmXUKO29/sT73owgtd5taUnAFU1Jus4CGwbGVFvQwsy/H9CpCl9tKIDGzUwn9+M0xnRDk5GRmY8xsuMV7JcXBnucD85MkebcZ6/omYbzKRwnjpQYQDtJ7KOBKEcIJrR9wC/CbJEmWp9KqCE3W68ysF2HsQGM88DUzaxcHil7ckBB/3f0QmGxmhwGYWScL9+nKPIFvF4O87oTxF7lMZ+cB6p0I56CVwGYz+yTw1fQCSZKsBZ4gBFyZQeS9gIuf3b5mtk8csPqFRsrQjjBOb02SJP80syMJXRcN63uD0GUyKe6P+wOZl5zfDNRaGDBuZtbBzAbF1szdaYyZHWNhYPJ4QgvUr2Nazn0gfqa3AzdaGLDfcIz1j7O8TWgdbtfIuh8CjjWzURYuUDiOsD/fXdQtbNyvCZ/dhLjvHkH4cm8owyzCPjXewoD7Ywhd4gAkSbKC0KJ9m8VL4M2ss5l92TJuX5JNkiRvAk8DU+JyNcAU4MkkSRpaXzxwTjxmuhPGd6Xlqut9CPtcBwsXAFxCGB9IkiSriAG8hStS+xNavzPzzXsgfZ6Kcaw0V7b6+Rsh2Bwaj/EvAyek0ov1uX+OcI5qEQVTUlaxafskQovFAsIXwrOEIARgDuGKuD8TWk3OJHy5NsccYIuZDWlknjWE7qRXzOx9wlidtYSxJ3mJJ5PTgMlJkryd/iO0rn3CzFwzyw5AkiT1hO0+hXAbgrRvEsZYrCOM+fpFE9mNI5x43yWMSZmWkf5fwAxghpm9RxgkfD6Nny/GANNiOXO5Dzg6flmQJMkrqXWtJQQA2VoI7iFs95z4hUZc/m3CLShOI3SLrCHUUdar0eIy64FvEQKL9YSWsMwu4/8gBCpvAHPZUZ8fxDx+Qrgo4J64zmWEL82KRra9GO4iBNNrgLMJY6Aa6rupfWAi4bOeHuf5PTtaqn5BaFl528IVV5ktUCRJ8hphPM04wmDf+wgD/R8t2tY1IW7ryYSA/B3CcX0voeu7IfA+lVA3awh1dXtGNucSLvb4nZmtI4wFHE7o3snHSEL9LYh/a4FRqfQrCD/+3iIEGg9nLJ+rrpcSWlheI5x7niLsYw2+RjgX1cftzQxibyb8sFhrZvPy3JZGFeNYaYFd6icJt1L5DmH/fxf4AmHQe0M5C/7czawzYf++o4XlDgO2RD7sYmvFhCRJTojvhxC+/PuUs1x7o9ia9VqSJBbfdwP+AriM8S7Zlj2fMID8q43Ntycxs88TAr4OSZlOmBbG5V2ROV5P9n5mNprw2Ra7Zank9oRjpSXM7HrCeL0Wt6xpALq0CkmSPEX4tSdFFrsheuc57x0U8OuvFMzsaMIv1pcIYy+uBR7Zm74cRErhw3KsJEnyvULzUDeftFZ17N13HC+ntYRB9R9WXQhdZesJXRd/J3QziMjOdKxE6uYTERERKYBapkREREQKoGBKREREpAAKpkREREQKoGBKREREpAAKpkREREQK8P8B8i9XoYdSKicAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x684 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.summary_plot(shap_values, features=X_test, feature_names=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_f =[]\n",
    "for x in y_pred:\n",
    "    y_pred_f.append(1-x)\n",
    "print(y_pred_f[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deneme =\"\"\n",
    "\n",
    "for x in y_pred_f:\n",
    "    deneme=deneme+\",\"+\"{:.4f}\".format(x)       \n",
    "deneme = deneme[1:]\n",
    "print(deneme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
